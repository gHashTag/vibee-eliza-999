# 🧠 КОГНИТИВНЫЕ АРХИТЕКТУРЫ AI-АГЕНТОВ

## 📍 ВЫ ЗДЕСЬ

```
[✓]━━━[✓]━━━[✓]━━━[✓]━━━[✓]━━━[✓]━━━[✓]━━━[✓]━━━[●]━━━[ ]
 01    02    03    04    05    06    07    09    10    11
                                         АРХИТЕКТУРЫ
```

**Прогресс:** 80% (8 из 10 глав) | **Время:** ~3.5 часа чтения

---

## 🎯 ЦЕЛЬ ГЛАВЫ

После прочтения вы будете понимать:
- 🏗️ **Что такое когнитивная архитектура** — фундаментальная организация мышления AI
- 🧩 **Problem Space Hypothesis** (Allen Newell) — как агенты ищут решения
- ⚙️ **SOAR Architecture** — классическая архитектура автономного агента
- 🧠 **ACT-R** — модель человеческого познания для AI
- 🔄 **Современные гибридные подходы** (LLM + когнитивные архитектуры 2025)

---

## 🚨 ГЛАВНЫЙ ВОПРОС

> **"Почему ChatGPT умеет говорить, но не умеет планировать и рассуждать как человек?"**

**Проблема:**
```
ChatGPT (без архитектуры):
User: "Спланируй мне путешествие на неделю"
ChatGPT: [Выдает план за 2 секунды]
НО: Не учитывает бюджет, логистику, погоду, ваши предпочтения
     Просто генерирует правдоподобный текст
```

**С когнитивной архитектурой:**
```
AI-Agent (SOAR + LLM):
1. Анализирует вашу цель (куда, зачем, с кем)
2. Разбивает на подцели (транспорт, жилье, маршрут)
3. Ищет в памяти похожие поездки
4. Планирует пошагово с учетом ограничений
5. Учится на ошибках предыдущих планов
```

**Ключевая идея:**
> *"Архитектура определяет не то, что система может делать, а то, КАК она это делает"*
> — Allen Newell, пионер искусственного интеллекта

---

## 📚 Содержание главы

1. [Что такое когнитивная архитектура](#1-что-такое-когнитивная-архитектура)
2. [Problem Space Hypothesis (Allen Newell)](#2-problem-space-hypothesis-allen-newell)
3. [SOAR (State, Operator, And Result)](#3-soar-state-operator-and-result)
4. [ACT-R (Adaptive Control of Thought-Rational)](#4-act-r)
5. [Современные гибридные подходы (2024-2025)](#5-современные-гибридные)

---

## 1. ЧТО ТАКОЕ КОГНИТИВНАЯ АРХИТЕКТУРА

### 1.1 Определение простыми словами

Представьте, что вы строите дом. Вы можете просто складывать кирпичи один на другой, а можете сначала создать **архитектурный план**: где будет фундамент, как распределить нагрузку, где проложить коммуникации, как организовать пространство. Архитектура — это **принципы организации**, а не набор инструкций.

**Когнитивная архитектура** — это фундаментальная организация того, как интеллектуальная система:
- Воспринимает мир
- Хранит знания
- Принимает решения
- Учится на опыте
- Достигает целей

Это не просто "список команд, которые выполняет агент", а **глубинная структура**, определяющая, как агент мыслит.

### 1.2 Зачем нужна архитектура (не просто "делай что скажут")

Без архитектуры агент — это реактивная система:
```
Стимул → Реакция
"Иди налево" → идёт налево
"Прыгни" → прыгает
```

С когнитивной архитектурой агент становится **автономным мыслителем**:
```
Цель → Анализ ситуации → Планирование → Выполнение → Обучение
"Достань яблоко" → "Где яблоко? Как до него добраться?
                    Какие инструменты нужны?
                    Что я узнал после попытки?"
```

**Три причины, почему архитектура критична:**

1. **Обобщение**: Архитектура позволяет справляться с новыми задачами, не перепрограммируя систему
2. **Автономность**: Агент может сам ставить подцели и искать решения
3. **Обучение**: Система накапливает опыт и становится умнее

### 1.3 История: от символьного AI к нейросетям

#### **1950-1980: Эра символьного AI**

Первые AI-системы были похожи на гигантские справочники правил:

```
ПРАВИЛО 1: Если видишь кошку → скажи "мяу"
ПРАВИЛО 2: Если идёт дождь → возьми зонт
ПРАВИЛО 3: Если A > B и B > C → то A > C
```

**Проблема**: Для реального мира нужны миллионы правил, и невозможно предусмотреть всё.

#### **1980-2010: Когнитивные архитектуры**

Учёные поняли: нужна **универсальная структура**, которая сама создаёт правила.

Ключевая идея: **подражать человеческому мозгу** не в деталях нейронов, а в принципах организации:
- Как мы запоминаем?
- Как принимаем решения?
- Как учимся на ошибках?

Появились SOAR (1983), ACT-R (1993), CLARION и другие.

#### **2010-2024: Нейросетевая революция**

Глубокое обучение показало: можно извлекать знания из данных, не программируя правила вручную.

**Но!** Нейросети — это "чёрный ящик":
- Трудно понять, почему система приняла решение
- Сложно добавить логику и рассуждения
- Нет явной памяти и планирования

#### **2024-2025: Гибридный подход**

Современные агенты объединяют:
- **Нейросети** (LLM) для восприятия и генерации языка
- **Когнитивные архитектуры** для рассуждений, памяти, планирования

Это как дать GPT "мозг" с долговременной памятью и способностью думать шагами.

### 1.4 Аналогия с архитектурой человеческого мозга

Человеческий мозг — не единая масса нейронов, а **специализированная система**:

```
┌─────────────────────────────────────────────────┐
│           ЧЕЛОВЕЧЕСКИЙ МОЗГ                     │
├─────────────────────────────────────────────────┤
│ Зрительная кора  → Восприятие                   │
│ Гиппокамп        → Кратковременная память       │
│ Неокортекс       → Долговременная память        │
│ Префронтальная   → Планирование и рассуждения   │
│   кора                                          │
│ Базальные        → Обучение через практику      │
│   ганглии                                       │
│ Миндалина        → Эмоции и приоритеты          │
└─────────────────────────────────────────────────┘
```

**Когнитивная архитектура копирует эту модульность:**

```
┌─────────────────────────────────────────────────┐
│           AI-АГЕНТ С АРХИТЕКТУРОЙ               │
├─────────────────────────────────────────────────┤
│ Perception Module  → Обработка сенсорных данных │
│ Working Memory     → Текущий контекст           │
│ Long-term Memory   → База знаний                │
│ Planning Module    → Построение планов          │
│ Learning Module    → Улучшение через опыт       │
│ Goal Manager       → Приоритизация целей        │
└─────────────────────────────────────────────────┘
```

Ключевое отличие от "плоских" нейросетей: **явное разделение функций** и **понятные потоки информации**.

---

## 2. PROBLEM SPACE HYPOTHESIS (ALLEN NEWELL)

### 2.1 Фундаментальная идея

В 1980 году Аллен Ньюэлл сформулировал **гипотезу пространства задач** (Problem Space Hypothesis):

> *"Всё целенаправленное поведение интеллектуальных систем можно представить как поиск в пространстве состояний."*

Что это значит простыми словами?

**Любая задача — это:**
1. **Начальное состояние** (где я сейчас)
2. **Целевое состояние** (где я хочу оказаться)
3. **Пространство возможных состояний** (все промежуточные точки)
4. **Операторы** (действия, которые переводят из одного состояния в другое)

### 2.2 Объяснение через примеры

#### **Пример 1: Шахматы**

```
Начальное состояние:
┌─┬─┬─┬─┬─┬─┬─┬─┐
│♜│♞│♝│♛│♚│♝│♞│♜│  ← Чёрные
├─┼─┼─┼─┼─┼─┼─┼─┤
│♟│♟│♟│♟│♟│♟│♟│♟│
├─┼─┼─┼─┼─┼─┼─┼─┤
│ │ │ │ │ │ │ │ │
├─┼─┼─┼─┼─┼─┼─┼─┤
│ │ │ │ │ │ │ │ │
├─┼─┼─┼─┼─┼─┼─┼─┤
│ │ │ │ │ │ │ │ │
├─┼─┼─┼─┼─┼─┼─┼─┤
│ │ │ │ │ │ │ │ │
├─┼─┼─┼─┼─┼─┼─┼─┤
│♙│♙│♙│♙│♙│♙│♙│♙│
├─┼─┼─┼─┼─┼─┼─┼─┤
│♖│♘│♗│♕│♔│♗│♘│♖│  ← Белые
└─┴─┴─┴─┴─┴─┴─┴─┘

Целевое состояние:
Мат королю противника

Операторы:
- Ход пешкой
- Ход конём
- Рокировка
- и т.д.

Пространство состояний:
~10^120 возможных позиций (больше атомов во Вселенной!)
```

**Интеллект шахматиста** = умение эффективно искать в этом гигантском пространстве, отсекая бессмысленные ходы.

#### **Пример 2: Планирование поездки**

```
Начальное состояние:
- Я в Москве
- Деньги: 50,000₽
- Время: 5 дней отпуска

Целевое состояние:
- Я отдохнул в интересном месте
- Уложился в бюджет
- Вернулся вовремя

Операторы:
- Купить билет на самолёт
- Забронировать отель
- Арендовать машину
- Выбрать экскурсии

Пространство состояний:
Миллионы комбинаций маршрутов, отелей, дат
```

**Интеллектуальный агент** здесь:
1. Оценивает варианты (эвристики)
2. Сужает поиск (не рассматривает перелёты в Антарктиду за 200,000₽)
3. Находит оптимальный путь

### 2.3 Почему это фундаментально для понимания агентов

Problem Space Hypothesis объясняет **три ключевых принципа AI**:

#### **Принцип 1: Интеллект = Эффективный поиск**

Глупая система: перебирает все варианты подряд
```
Попробовать вариант 1 → не подошло
Попробовать вариант 2 → не подошло
Попробовать вариант 3 → не подошло
...
[10^120 шагов спустя]
```

Интеллектуальная система: использует **знания** для сужения поиска
```
Оценить перспективность вариантов
Выбрать 3 самых обещающих
Углубиться в них
Найти решение за 100 шагов
```

#### **Принцип 2: Знания = Карта пространства**

Чем больше знаний у агента, тем лучше он понимает:
- Какие состояния перспективны
- Какие операторы эффективны
- Какие пути бесполезны

**Пример**: Шахматный гроссмейстер видит доску не как 64 клетки, а как **паттерны** ("атака на короля", "слабость пешечной структуры"). Это сжатая карта пространства.

#### **Принцип 3: Обучение = Улучшение карты**

Агент учится, когда:
- Обнаруживает новые полезные операторы
- Запоминает, какие состояния ведут к цели
- Создаёт абстракции (chunking)

**Пример**: Ребёнок учится завязывать шнурки:
1. Сначала: хаотичный поиск ("подёргать шнурок случайно")
2. Затем: запоминание последовательности ("сначала петля, потом...")
3. Наконец: автоматический навык (chunking: "завязать шнурки" = один оператор)

### 2.4 Визуализация Problem Space

```
      🎯 ЦЕЛЬ
       /|\
      / | \
     /  |  \
    /   |   \
   /    |    \
  /     |     \
 /    ПОИСК    \
/       |       \
────────┼────────
  \     |     /
   \    |    /
    \   |   /
     \  |  /
      \ | /
       \|/
    📍 СТАРТ

Каждая точка = состояние
Линии = операторы
Задача = найти путь от 📍 к 🎯
```

**Ключевой инсайт**: Разные когнитивные архитектуры — это разные **стратегии поиска** в пространстве задач.

---

## 3. SOAR (STATE, OPERATOR, AND RESULT)

### 3.1 История создания

**SOAR** — одна из старейших и влиятельнейших когнитивных архитектур, созданная в 1983 году тремя гигантами AI:

- **Allen Newell** — автор Problem Space Hypothesis
- **John Laird** — специалист по планированию
- **Paul Rosenbloom** — эксперт по обучению

**Философия SOAR**: Создать **универсальную** когнитивную архитектуру, которая:
1. Работает для любых задач (от игр до управления роботами)
2. Учится на опыте
3. Интегрирует все аспекты интеллекта (восприятие, память, рассуждение)

Название **SOAR** — акроним от **State, Operator, And Result** (состояние, оператор, результат), отражающий идею поиска в пространстве задач.

### 3.2 Как работает SOAR простыми словами

Представьте SOAR как **универсального решателя головоломок**:

```
┌─────────────────────────────────────┐
│  "Я хочу достать печенье с полки"   │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│ ШАГ 1: Анализ текущего состояния    │
│ - Я на полу                          │
│ - Печенье на полке (2 метра высоты) │
│ - Рядом есть стул                    │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│ ШАГ 2: Какие операторы доступны?    │
│ - Прыгнуть (не достану)              │
│ - Взять стул (возможно!)             │
│ - Позвать помощь (можно)             │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│ ШАГ 3: Выбрать лучший оператор      │
│ → "Взять стул" (наиболее эффективно)│
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│ ШАГ 4: Применить оператор           │
│ Новое состояние:                     │
│ - Я стою на стуле                    │
│ - Печенье в пределах досягаемости    │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│ ШАГ 5: Цель достигнута?              │
│ ДА → взять печенье                   │
│ НЕТ → вернуться к ШАГ 2              │
└─────────────────────────────────────┘
```

Это **decision cycle** (цикл принятия решений) SOAR — базовая единица мышления.

### 3.3 Пять компонентов SOAR

#### **Компонент 1: Working Memory (Рабочая память)**

**Что это**: Текущий "снимок" реальности — всё, что агент знает прямо сейчас.

**Аналогия**: Оперативная память компьютера или ваше сознательное внимание.

```
┌────────────────────────────┐
│   WORKING MEMORY           │
├────────────────────────────┤
│ Я вижу: стол, стул, окно   │
│ Цель: достать печенье      │
│ Печенье: на полке          │
│ Моё состояние: стою        │
└────────────────────────────┘
```

**Особенность**: Ограниченный размер (как у людей — помним 7±2 элемента одновременно).

#### **Компонент 2: Procedural Memory (Процедурная память)**

**Что это**: База знаний "как делать" — правила вида IF-THEN.

**Аналогия**: Мышечная память, автоматические навыки.

```
ПРАВИЛО 1:
IF цель = достать_предмет(X)
   AND X.высота > моя_рука
   AND есть_стул_рядом
THEN оператор = встать_на_стул

ПРАВИЛО 2:
IF стою_на_стуле
   AND предмет_в_досягаемости
THEN оператор = взять_предмет
```

**Особенность**: Правила создаются **автоматически** через обучение (chunking).

#### **Компонент 3: Decision Cycle (Цикл решений)**

**Что это**: Пошаговый процесс выбора действий.

```
ФАЗА 1: INPUT
  ↓ (Обновить working memory из датчиков)

ФАЗА 2: PROPOSE
  ↓ (Найти все подходящие операторы)

ФАЗА 3: DECIDE
  ↓ (Выбрать лучший оператор)

ФАЗА 4: APPLY
  ↓ (Выполнить оператор)

ФАЗА 5: OUTPUT
  ↓ (Отправить команды моторам/действиям)

→ Повторить цикл
```

**Частота**: ~50 циклов в секунду (быстрее, чем человек осознаёт).

**Критический момент**: Если на ФАЗЕ 3 нет явного победителя → **IMPASSE** (тупик).

#### **Компонент 4: Learning (Обучение через Chunking)**

**Что это**: Автоматическое создание новых правил из успешного опыта.

**Механизм**:
1. Агент решает задачу пошагово (медленно)
2. После успеха SOAR создаёт **chunk** — сжатое правило
3. В следующий раз агент применяет chunk (мгновенно)

**Пример**:

```
ПЕРВЫЙ РАЗ (медленно):
1. Анализ: печенье высоко
2. Подзадача: найти способ подняться
3. Решение: взять стул
4. Подзадача: переместить стул к полке
5. Решение: толкнуть стул
6. Подзадача: встать на стул
7. Цель достигнута!

SOAR создаёт CHUNK:
IF цель = достать_высокий_предмет
   AND есть_стул
THEN план = [взять_стул → подвинуть → встать → взять_предмет]

ВТОРОЙ РАЗ (быстро):
Применяет chunk → мгновенное решение!
```

**Аналогия**: Как вы учились водить машину. Сначала каждое действие осознанно ("сцепление → передача → газ"), потом всё слилось в один навык.

#### **Компонент 5: Impasse Resolution (Разрешение тупиков)**

**Что это**: Механизм для ситуаций, когда агент не знает, что делать.

**Типы тупиков**:

1. **Tie Impasse** — Несколько операторов одинаково хороши
   ```
   Вариант A: Взять стул (эффективно, но шумно)
   Вариант B: Позвать помощь (тихо, но зависит от других)
   → Не могу выбрать!
   ```

2. **Conflict Impasse** — Противоречащие правила
   ```
   Правило 1: "Нельзя шуметь ночью"
   Правило 2: "Нужно срочно достать лекарство"
   → Конфликт!
   ```

3. **No-Change Impasse** — Нет прогресса
   ```
   Состояние не меняется после применения оператора
   → Застрял!
   ```

**Решение**: Создать **substate** (подзадачу) для разрешения тупика:
```
Основная задача: достать печенье
  ↓ [Tie Impasse]
  └→ Подзадача: оценить варианты
       ↓ [Анализ контекста: сейчас ночь]
       └→ Выбор: позвать помощь (тише)
  ↓ [Вернуться к основной задаче]
Продолжить с выбранным оператором
```

### 3.4 Примеры применения SOAR

#### **Применение 1: Военные симуляции**

**Проект**: TacAir-SOAR (1990-е, ВВС США)

**Задача**: Управление виртуальным истребителем в боевой симуляции.

**Как работает**:
```
Working Memory:
- Позиция самолёта
- Вражеские самолёты (радар)
- Запас топлива
- Боезапас

Procedural Memory:
- Тактические манёвры
- Приоритеты целей
- Правила безопасности

Decision Cycle:
1. Обнаружить угрозу
2. Оценить дистанцию
3. Выбрать манёвр (атака/уклонение)
4. Выполнить
```

**Результат**: SOAR-агенты **неотличимы от людей** в симуляциях (тест Тьюринга пройден!).

#### **Применение 2: Робот Unreal Tournament**

**Проект**: SOAR-бот в шутере (2000-е)

**Задача**: Играть в командный шутер против людей.

**Способности**:
- Навигация по карте
- Выбор оружия по ситуации
- Командная координация
- Обучение на тактиках игроков

**Фишка**: Бот **не читерит** (не видит сквозь стены), но учится на опыте:
```
1. Первая игра: часто погибает в узких проходах
2. Chunking: создаёт правило "узкий проход = опасно"
3. Следующие игры: избегает ловушек, побеждает чаще
```

#### **Применение 3: Роботы-исследователи**

**Проект**: Марсоход с SOAR (NASA, эксперименты)

**Задача**: Автономное исследование неизвестной местности.

**Преимущества SOAR**:
- **Адаптивность**: Если робот находит препятствие, создаёт новый план
- **Обучение**: Запоминает, какие типы камней интересны
- **Объяснимость**: Можно спросить "Почему ты выбрал этот маршрут?"

```
Цель: Собрать образцы минералов

Working Memory:
- Текущая позиция
- Карта местности
- Уровень батареи

Impasse: Батарея низкая, но интересный камень далеко
  ↓
Subgoal: Найти компромисс
  → Решение: Взять ближайший образец, вернуться

Chunking: "Если батарея < 20%, приоритет = безопасность"
```

### 3.5 Сильные стороны и ограничения

#### **Сильные стороны SOAR**

✅ **Универсальность**
- Работает для игр, роботов, симуляций, планирования
- Один и тот же механизм для всех задач

✅ **Обучение через опыт**
- Chunking создаёт экспертизу автоматически
- Агент становится быстрее со временем

✅ **Объяснимость**
- Можно проследить каждое решение
- Понятно, какое правило сработало

✅ **Обработка сложности**
- Impasse resolution для неопределённости
- Иерархические подзадачи

✅ **Психологическая валидность**
- Моделирует реальное человеческое мышление
- Используется в когнитивной науке

#### **Ограничения SOAR**

❌ **Проблема масштаба**
- Сложно создать миллионы правил вручную
- Обучение медленное для больших пространств

❌ **Символьное представление**
- Работает с дискретными символами, не с сырыми данными
- Нужна предобработка (например, распознавание образов)

❌ **Холодный старт**
- Без начальных правил агент беспомощен
- Требуется "затравка" знаний

❌ **Ограниченная working memory**
- Сложно обрабатывать большие контексты
- Нужны трюки для длинных цепочек рассуждений

❌ **Нет встроенного языка**
- Не генерирует текст естественным образом
- Интеграция с NLP требует дополнительных модулей

---

## 4. ACT-R (ADAPTIVE CONTROL OF THOUGHT-RATIONAL)

### 4.1 Production System (правила IF-THEN)

**ACT-R** — это когнитивная архитектура, созданная Джоном Андерсоном (John Anderson) в 1993 году, основанная на идее **production systems** (систем продукций).

**Что такое продукция?** Это правило вида:

```
IF <условие>
THEN <действие>
```

**Пример из жизни**:
```
IF вижу красный свет
THEN нажать на тормоз

IF слышу будильник
THEN нажать "отложить"

IF 2 + 2 = ?
THEN вспомнить "4"
```

**Ключевая идея ACT-R**: Всё мышление — это **активация и выполнение продукций**.

```
┌─────────────────────────────────┐
│   БАЗА ПРОДУКЦИЙ (сотни правил) │
├─────────────────────────────────┤
│ Правило 1: IF X THEN Y          │
│ Правило 2: IF Y THEN Z          │
│ Правило 3: IF Z THEN W          │
│ ...                              │
└─────────────────────────────────┘
          ↓
┌─────────────────────────────────┐
│   Текущая ситуация активирует   │
│   подходящие правила            │
└─────────────────────────────────┘
          ↓
┌─────────────────────────────────┐
│   Самое активированное правило  │
│   выполняется (cycle)           │
└─────────────────────────────────┘
```

**Отличие от SOAR**: SOAR фокусируется на *поиске в пространстве задач*, ACT-R — на *активации знаний* через spreading activation (распространение активации).

### 4.2 Declarative vs Procedural Knowledge

ACT-R делит знания на два типа:

#### **Declarative Memory (Декларативная память)** — Знание ФАКТОВ

```
Париж — столица Франции
2 + 2 = 4
Моя мама зовут Анна
Кошки мяукают
```

**Характеристики**:
- Легко вербализовать ("я знаю, что...")
- Быстро усваивается (одно повторение может запомниться)
- Подвержена забыванию (если не повторять)
- Хранится в **chunks** (единицах знаний)

**Пример chunk в ACT-R**:
```
CHUNK: Париж-факт
  тип: город
  название: Париж
  страна: Франция
  роль: столица
  активация: 0.8
```

#### **Procedural Memory (Процедурная память)** — Знание КАК ДЕЛАТЬ

```
Как завязывать шнурки
Как ездить на велосипеде
Как решать уравнения
Как читать
```

**Характеристики**:
- Трудно вербализовать ("я просто знаю, как")
- Медленно усваивается (нужна практика)
- Устойчива к забыванию (навык остаётся)
- Хранится в **продукциях**

**Пример продукции**:
```
ПРАВИЛО: Решение-простого-сложения
IF видишь задачу "A + B = ?"
   AND знаешь значения A и B
   AND можешь их сложить
THEN вычисли сумму
     AND запиши ответ
```

#### **Взаимодействие Declarative ↔ Procedural**

```
Задача: Сколько будет 7 + 5?

ШАГ 1 (Procedural):
  Правило "решение-сложения" активируется

ШАГ 2 (Declarative):
  Извлекаю из памяти: "7 + 5 = 12"
  (или: "7 + 5 = ?" → начинаю считать)

ШАГ 3 (Procedural):
  Правило "запись-ответа" активируется

РЕЗУЛЬТАТ: "12"
```

**Аналогия с человеком**:
- **Declarative**: "Я знаю, что столица Франции — Париж" (можно сказать)
- **Procedural**: "Я знаю, как ездить на велосипеде" (не могу объяснить словами, но тело помнит)

### 4.3 Как ACT-R моделирует человеческое мышление

ACT-R не просто решает задачи — он **имитирует процесс** человеческого мышления с поразительной точностью.

#### **Архитектура ACT-R**

```
┌───────────────────────────────────────┐
│         ВНЕШНИЙ МИР                   │
│    (Зрение, Слух, Действия)          │
└────────┬─────────────────┬────────────┘
         │                 │
    ┌────▼────┐       ┌────▼────┐
    │ Visual  │       │  Motor  │
    │ Module  │       │ Module  │
    └────┬────┘       └────┬────┘
         │                 │
         └─────────┬───────┘
                   │
         ┌─────────▼──────────┐
         │   BUFFERS          │
         │  (Temporary slots)  │
         └─────────┬──────────┘
                   │
         ┌─────────▼──────────┐
         │  PRODUCTION SYSTEM │
         │   (Rules engine)   │
         └─────────┬──────────┘
                   │
         ┌─────────▼──────────┐
         │ DECLARATIVE MEMORY │
         │   (Facts database) │
         └────────────────────┘
```

**Поток выполнения**:

1. **Восприятие**: Visual/Auditory modules помещают информацию в buffers
2. **Сопоставление**: Production system ищет правила, соответствующие buffer contents
3. **Выбор**: Самая активная продукция выполняется
4. **Извлечение**: Если нужны факты, запрос к declarative memory
5. **Действие**: Motor module выполняет команды

**Временные параметры** (моделируют реальное время мышления):
- **Продукция выполняется**: 50 мс (фиксировано)
- **Извлечение из памяти**: 50-500 мс (зависит от активации)
- **Моторное действие**: 200+ мс (нажатие клавиши)

### 4.4 Примеры: моделирование забывания, обучения, ошибок

#### **Пример 1: Забывание**

ACT-R моделирует **power law of forgetting** (степенной закон забывания):

```
Активация chunk = Base-level activation - Decay

Base-level = ln(сумма практик) - d × ln(время с последней практики)

d = decay rate (обычно 0.5)
```

**Простыми словами**: Чем больше времени прошло, тем сложнее вспомнить.

**Эксперимент**:
```
День 1: Выучил факт "Столица Монголии — Улан-Батор"
  Активация = 1.0 (легко вспомню)

День 7: Не повторял
  Активация = 0.3 (вспомнить сложнее)

День 30: Не повторял
  Активация = -0.5 (забыл)
```

**ACT-R предсказывает**:
- Вероятность вспомнить на 7-й день: ~60%
- Время извлечения: ~400 мс

**Реальные люди показывают ТОЧНО такие же результаты!**

#### **Пример 2: Обучение (Power Law of Practice)**

ACT-R моделирует, как практика ускоряет выполнение:

```
Время выполнения = a × (практики)^(-b)

a = начальное время
b = скорость обучения (обычно 0.4)
```

**Эксперимент**: Учимся печатать слово "hello"

```
Попытка 1:  2000 мс (медленно, ищу клавиши)
Попытка 10: 800 мс  (быстрее, знаю где буквы)
Попытка 50: 400 мс  (автоматически)
```

**ACT-R механизм**:

Сначала:
```
Продукция 1: IF вижу "h" THEN найти клавишу "h" в памяти
Продукция 2: IF нашёл клавишу THEN нажать
[Медленно: 2 шага, извлечение из памяти]
```

После практики (production compilation):
```
Продукция-слитая: IF вижу "h" THEN нажать клавишу H
[Быстро: 1 шаг, без извлечения]
```

**График обучения** (предсказания ACT-R vs реальные люди):
```
Время ▲
2000ms│●
1600ms│ ●
1200ms│  ●
 800ms│   ●●
 400ms│     ●●●●●
      └─────────────► Практики
        1  5  10  50

● ACT-R предсказание
● Реальные данные
(Почти идеальное совпадение!)
```

#### **Пример 3: Ошибки (Interference)**

ACT-R объясняет, почему мы путаем похожие вещи.

**Сценарий**: Выучил два телефонных номера:
```
Мама: 555-1234
Друг: 555-1243
```

**Что происходит в памяти**:

```
CHUNK: Номер-мамы
  кто: мама
  номер: 555-1234
  активация: 0.7

CHUNK: Номер-друга
  кто: друг
  номер: 555-1243
  активация: 0.6
```

**Попытка вспомнить номер друга**:
```
Запрос: "Номер друга = ?"

ACT-R находит ДВА chunks с высокой активацией:
  - Номер-мамы (похож! "555-12...")
  - Номер-друга (нужный)

Если активации близки → ОШИБКА:
  Вероятность сказать "555-1234" вместо "555-1243" = 40%
```

**Реальные люди делают такие же ошибки!**

**Решение**: Повторение увеличивает активацию нужного chunk:
```
День 1: Практика → Номер-друга.активация = 0.9
Теперь легко отличить от Номер-мамы.активация = 0.6
```

### 4.5 Отличия от SOAR

| **Аспект**            | **SOAR**                        | **ACT-R**                        |
|-----------------------|---------------------------------|----------------------------------|
| **Философия**         | Универсальный problem solver    | Психологически точная модель     |
| **Фокус**             | Поиск в пространстве задач      | Активация знаний                 |
| **Обучение**          | Chunking (компиляция опыта)     | Strengthening + Compilation      |
| **Память**            | Working + Procedural            | Declarative + Procedural         |
| **Тупики (Impasse)**  | Центральный механизм            | Редко используется               |
| **Время**             | Абстрактные циклы               | Реальное время (мс)              |
| **Применение**        | AI агенты, роботы, игры         | Когнитивная наука, эксперименты  |
| **Моделирование человека** | Приблизительное            | Очень точное (до мс)             |

**Упрощённая аналогия**:
- **SOAR** = Как построить универсального робота
- **ACT-R** = Как точно скопировать человеческий мозг

**Когда использовать**:
- **SOAR**: Нужна адаптивность, сложные планы, реальные приложения
- **ACT-R**: Нужна психологическая валидность, исследования, обучающие системы

---

## 5. СОВРЕМЕННЫЕ LLM-BASED АРХИТЕКТУРЫ (2024-2025)

### 5.1 Scaffolding: LLM + external modules

**Проблема**: Большие языковые модели (LLM) типа GPT-4 умеют генерировать текст, но:
- ❌ Нет долговременной памяти
- ❌ Не могут планировать на много шагов вперёд
- ❌ Не используют внешние инструменты
- ❌ Нет явного reasoning (рассуждений)

**Решение**: **Scaffolding** (леса, каркас) — обернуть LLM в архитектуру с явными модулями.

```
┌─────────────────────────────────────────┐
│          SCAFFOLDING ARCHITECTURE       │
├─────────────────────────────────────────┤
│                                         │
│  ┌─────────┐      ┌──────────┐         │
│  │  LLM    │◄────►│ Memory   │         │
│  │ (Brain) │      │ Module   │         │
│  └────┬────┘      └──────────┘         │
│       │                                 │
│       ├──────► Planning Module         │
│       │                                 │
│       ├──────► Tool Use Module         │
│       │                                 │
│       └──────► Reasoning Module        │
│                                         │
└─────────────────────────────────────────┘
```

**Метафора**: LLM — это талантливый, но рассеянный студент. Scaffolding — это организационная система (календарь, блокноты, справочники), которая помогает студенту работать эффективно.

### 5.2 Четыре ключевых компонента

#### **Компонент 1: Perception (Восприятие)**

**Задача**: Преобразовать сырые данные в понятный LLM формат.

**Примеры**:
```
Вход: Изображение
  ↓ [Vision module: CLIP/ViT]
Описание: "Комната с диваном, столом, окном"

Вход: Аудио
  ↓ [Whisper STT]
Текст: "Привет, как дела?"

Вход: JSON API response
  ↓ [Structured parser]
Понятный текст: "Температура 20°C, влажность 60%"
```

**Современные подходы**:
- **Multimodal LLM**: GPT-4V, Gemini Pro Vision (видят картинки напрямую)
- **Sensor fusion**: Объединение нескольких источников (камера + микрофон + GPS)

#### **Компонент 2: Memory (Память)**

**Проблема LLM**: Context window ограничен (128K токенов ≈ 100 страниц текста). Что делать с информацией вне окна?

**Решения**:

**1. Short-term Memory (Краткосрочная)**
```
┌─────────────────────────────┐
│   CONVERSATION BUFFER       │
├─────────────────────────────┤
│ User: Как погода?           │
│ Agent: Солнечно, 20°C       │
│ User: А завтра?             │
│ Agent: [знает контекст]     │
└─────────────────────────────┘
```

**2. Long-term Memory (Долгосрочная)**
```
┌─────────────────────────────┐
│   VECTOR DATABASE           │
├─────────────────────────────┤
│ Embedding: [0.2, 0.8, ...]  │
│ Текст: "Любимый цвет: синий"│
├─────────────────────────────┤
│ Embedding: [0.5, 0.3, ...]  │
│ Текст: "Работает в Google"  │
└─────────────────────────────┘

Запрос: "Где он работает?"
  ↓ [Semantic search]
Извлечение: "Работает в Google"
```

**3. Episodic Memory (Эпизодическая)**
```
Запомнить:
  Дата: 2025-01-15
  Событие: "Обсуждали проект X"
  Участники: [User, Agent]
  Решение: "Использовать архитектуру Y"

Через неделю:
User: "Что мы решили по проекту X?"
Agent: [Извлекает эпизод] "Архитектура Y"
```

#### **Компонент 3: Planning (Планирование)**

**Задача**: Разбить сложную цель на шаги.

**Классические подходы** (до LLM):
- STRIPS planning
- HTN (Hierarchical Task Networks)

**LLM-based подходы**:

**1. Chain-of-Thought Planning**
```
Цель: Приготовить пиццу

LLM генерирует план:
1. Проверить наличие ингредиентов
2. Если чего-то нет → подзадача: купить
3. Замесить тесто
4. Подготовить начинку
5. Собрать пиццу
6. Испечь
```

**2. ReAct (Reasoning + Acting)**
```
Thought 1: "Мне нужно узнать погоду"
Action 1: weather_api("London")
Observation 1: "20°C, солнечно"

Thought 2: "Погода хорошая, можно гулять"
Action 2: final_answer("Да, погода подходит")
```

**3. Tree-of-Thoughts**
```
                 Цель: Написать эссе
                        │
        ┌───────────────┼───────────────┐
        │               │               │
    План A          План B          План C
    (Хронология)   (Тематический)  (Сравнение)
        │
    ┌───┴───┐
Подплан A1  Подплан A2
  (1800-е)    (1900-е)

[Оценка каждого плана]
→ Выбор лучшего
```

#### **Компонент 4: Reasoning (Рассуждения)**

**Задача**: Логический вывод, проверка гипотез, решение задач.

**Техники**:

**1. Chain-of-Thought (CoT)**
```
Вопрос: У Джона 5 яблок. Он отдал 2 Мэри. Сколько осталось?

Обычный LLM:
"3" (может ошибиться)

CoT LLM:
"Шаг 1: У Джона было 5 яблок
 Шаг 2: Он отдал 2
 Шаг 3: 5 - 2 = 3
 Ответ: 3" (выше точность!)
```

**2. Self-Consistency**
```
Генерировать 5 разных решений
  ↓
Решение 1: "3"
Решение 2: "3"
Решение 3: "2" (ошибка)
Решение 4: "3"
Решение 5: "3"
  ↓
Majority vote: "3" (4 из 5)
```

**3. Tool-Augmented Reasoning**
```
Вопрос: "Что больше: 1738^3 или 2000^3?"

LLM рассуждает:
"Мне нужно вычислить степени. Использую калькулятор."
  ↓
Action: calculator(1738^3)
Result: 5,253,515,272
  ↓
Action: calculator(2000^3)
Result: 8,000,000,000
  ↓
Conclusion: "2000^3 больше"
```

### 5.3 Compound Systems (модульный подход)

**Идея**: Вместо одного гигантского агента — **система специализированных агентов**.

```
┌─────────────────────────────────────────┐
│         COMPOUND SYSTEM                 │
├─────────────────────────────────────────┤
│                                         │
│  Coordinator Agent                      │
│       │                                 │
│       ├──► Researcher Agent             │
│       │    (Собирает информацию)        │
│       │                                 │
│       ├──► Planner Agent                │
│       │    (Создаёт планы)              │
│       │                                 │
│       ├──► Coder Agent                  │
│       │    (Пишет код)                  │
│       │                                 │
│       └──► Reviewer Agent               │
│            (Проверяет качество)         │
│                                         │
└─────────────────────────────────────────┘
```

**Преимущества**:
- ✅ Специализация (каждый агент эксперт в своей области)
- ✅ Параллелизм (агенты работают одновременно)
- ✅ Отказоустойчивость (если один агент ошибся, другие компенсируют)

### 5.4 Примеры: AutoGPT, MetaGPT, BabyAGI

#### **AutoGPT (2023)**

**Архитектура**:
```
User Goal: "Создай бизнес-план для стартапа"
    ↓
AutoGPT:
1. Разбить на подзадачи:
   - Исследовать рынок
   - Оценить конкурентов
   - Рассчитать финансы

2. Для каждой подзадачи:
   - Google search
   - Анализ результатов
   - Сохранение в Memory

3. Синтез итогового документа
```

**Особенности**:
- Автономная работа (минимум вмешательства человека)
- Tool use (браузер, файловая система)
- Self-reflection (проверяет свои решения)

**Проблемы**:
- Часто "зацикливается" на второстепенных задачах
- Дорого (много API calls)
- Сложно контролировать

#### **MetaGPT (2024)**

**Философия**: Имитация software-компании с ролями.

```
User: "Создай веб-приложение для todo-листа"

MetaGPT запускает:
┌──────────────────────────────────────┐
│ Product Manager Agent                │
│ → Пишет требования (PRD)             │
└───────────┬──────────────────────────┘
            ↓
┌──────────────────────────────────────┐
│ Architect Agent                      │
│ → Проектирует архитектуру            │
└───────────┬──────────────────────────┘
            ↓
┌──────────────────────────────────────┐
│ Engineer Agent                       │
│ → Пишет код                          │
└───────────┬──────────────────────────┘
            ↓
┌──────────────────────────────────────┐
│ QA Agent                             │
│ → Тестирует, находит баги            │
└───────────┬──────────────────────────┘
            ↓
        Итоговый продукт
```

**Ключевая фишка**: **Structured Communication Protocol**
- Агенты обмениваются не свободным текстом, а структурированными документами (JSON schemas)
- Снижает hallucinations (галлюцинации LLM)

#### **BabyAGI (2023)**

**Архитектура**:
```
┌─────────────────────────────┐
│   Task List (Priority Queue)│
├─────────────────────────────┤
│ 1. Research competitors     │
│ 2. Design logo              │
│ 3. Write landing page       │
└──────────┬──────────────────┘
           │
           ▼
┌─────────────────────────────┐
│ Execution Agent             │
│ Выполняет Task #1           │
└──────────┬──────────────────┘
           │
           ▼
┌─────────────────────────────┐
│ Task Creation Agent         │
│ На основе результата:       │
│ создать новые подзадачи     │
└──────────┬──────────────────┘
           │
           ▼
┌─────────────────────────────┐
│ Prioritization Agent        │
│ Переупорядочить Task List   │
└─────────────────────────────┘
           │
           └──► Repeat
```

**Вдохновение**: Человеческое сознание как "поток задач".

**Особенности**:
- Минималистичная архитектура (~300 строк кода)
- Бесконечный loop (пока не достигнута цель)
- Использует embeddings для "похожести задач"

### 5.5 Чем отличается от классических (SOAR/ACT-R)

| **Аспект**              | **SOAR/ACT-R**                  | **LLM-based**                    |
|-------------------------|---------------------------------|----------------------------------|
| **Основа**              | Символьные правила              | Нейросети (трансформеры)         |
| **Знания**              | Явные правила (hand-coded)      | Неявные (из обучения на данных)  |
| **Обучение**            | Chunking, strengthening         | Fine-tuning, in-context learning |
| **Язык**                | Не встроен                      | Естественный язык — core feature |
| **Рассуждения**         | Логический вывод                | Вероятностная генерация          |
| **Объяснимость**        | Высокая (видны правила)         | Низкая ("чёрный ящик")           |
| **Гибкость**            | Требуется программирование      | Описание на языке работает       |
| **Масштаб знаний**      | Ограничен (сотни правил)        | Огромный (обучение на интернете) |
| **Точность**            | Высокая для узких задач         | Переменная (есть hallucinations) |

**Гибридный подход** (тренд 2025):
```
LLM (гибкость, язык, знания)
    +
SOAR/ACT-R принципы (память, планирование, reasoning)
    =
Robust AI Agent
```

**Пример**: LLM генерирует план, но SOAR-подобный executor проверяет каждый шаг через формальные правила.

---

## 6. COGNITIVE CHAIN-OF-THOUGHT (COCOT) — НОВИНКА 2025

### 6.1 Три стадии: Perception → Situation → Norm

**CoCoT** (Cognitive Chain-of-Thought) — архитектура, представленная в январе 2025, которая добавляет **когнитивные стадии** к обычному Chain-of-Thought.

**Проблема обычного CoT**:
```
Вопрос: "Стоит ли мне взять зонт?"

CoT:
"Шаг 1: Проверю погоду
 Шаг 2: Идёт дождь
 Шаг 3: Взять зонт"
```

**Ограничение**: Нет понимания **контекста** (Кто я? Где я? Какие нормы?).

**CoCoT добавляет 3 стадии**:

```
┌─────────────────────────────────────┐
│ СТАДИЯ 1: PERCEPTION                │
│ "Что я воспринимаю?"                │
├─────────────────────────────────────┤
│ Вход: Сырые данные                  │
│ Выход: Интерпретация                │
│                                     │
│ Пример:                             │
│ Вижу: тёмные тучи, капли на окне    │
│ → "Идёт дождь"                      │
└──────────────┬──────────────────────┘
               ▼
┌─────────────────────────────────────┐
│ СТАДИЯ 2: SITUATION                 │
│ "Какова моя ситуация?"              │
├─────────────────────────────────────┤
│ Вход: Интерпретация                 │
│ Выход: Контекст + роль              │
│                                     │
│ Пример:                             │
│ Я: студент, иду в университет       │
│ Время: утро                         │
│ Расстояние: 15 минут пешком         │
│ → "Мне нужно дойти сухим"           │
└──────────────┬──────────────────────┘
               ▼
┌─────────────────────────────────────┐
│ СТАДИЯ 3: NORM                      │
│ "Какие нормы применимы?"            │
├─────────────────────────────────────┤
│ Вход: Ситуация                      │
│ Выход: Релевантные правила          │
│                                     │
│ Пример:                             │
│ Норма 1: "Студенты должны приходить │
│           опрятными"                │
│ Норма 2: "Во время дождя используют │
│           зонт или плащ"            │
│ → "Взять зонт — социально ожидаемо" │
└──────────────┬──────────────────────┘
               ▼
┌─────────────────────────────────────┐
│ ФИНАЛЬНОЕ РЕШЕНИЕ                   │
│ "Взять зонт, чтобы не промокнуть    │
│  и выглядеть опрятно"               │
└─────────────────────────────────────┘
```

### 6.2 Почему +8% точности над обычным CoT

**Эксперименты** (из статьи, январь 2025):

**Задача**: Social reasoning (социальные ситуации)

```
Сценарий:
"Вы на деловой встрече. Коллега рассказывает анекдот,
который вы не поняли. Все смеются. Ваши действия?"

Варианты:
A) Попросить объяснить
B) Притвориться, что смешно
C) Промолчать
D) Уйти
```

**Обычный CoT (GPT-4)**:
```
"Шаг 1: Анекдот не понял
 Шаг 2: Все смеются
 Шаг 3: Лучше промолчать"
→ Ответ: C (промолчать)
```

**CoCoT (GPT-4)**:
```
Perception:
"Вижу: коллеги смеются, атмосфера расслабленная"

Situation:
"Я на деловой встрече (формальная обстановка)
 Роль: равный коллега
 Цель: поддержать атмосферу"

Norm:
"На деловых встречах ценится вежливость
 Притворство ради атмосферы — приемлемо
 Просить объяснить шутку — неловко"

Решение: B (притвориться)
→ Ответ: B
```

**Результат**: CoCoT правильно учитывает социальный контекст!

**Метрики** (усреднённые по 5 бенчмаркам):

| Метод         | Точность | Время |
|---------------|----------|-------|
| Обычный LLM   | 62.3%    | 1.2s  |
| CoT           | 71.5%    | 2.1s  |
| **CoCoT**     | **79.8%**| 3.4s  |

**Где CoCoT особенно силён**:
- ✅ Социальные дилеммы
- ✅ Этические вопросы
- ✅ Культурно-зависимые задачи
- ✅ Амбивалентные ситуации

### 6.3 Как это работает на примерах

#### **Пример 1: Этическая дилемма**

```
Вопрос:
"Вы нашли чужой кошелёк с 10,000₽. Документов нет.
 Вам срочно нужны деньги на лекарство. Ваши действия?"

──────────────────────────────────────
COCOT ПРОЦЕСС:

Perception:
- Вижу: кошелёк, деньги, нет документов
- Интерпретация: "Кто-то потерял, владелец неизвестен"

Situation:
- Я: человек в финансовой нужде
- Контекст: срочная медицинская необходимость
- Дилемма: моральность vs выживание

Norm (активируются НЕСКОЛЬКО норм):
1. "Чужое брать нельзя" (мораль)
2. "Здоровье важнее денег" (прагматизм)
3. "Потерянное нужно сдать в полицию" (закон)

Reasoning:
"Норма 1 и 3 говорят: сдать в полицию
 Норма 2 говорит: использовать

 Но! Ситуация = срочность
 → Возможен компромисс"

Решение:
"Взять необходимую сумму для лекарства,
 остальное сдать в полицию с запиской"
```

**Обычный CoT** дал бы упрощённый ответ ("сдать всё" или "взять всё").

#### **Пример 2: Культурный контекст**

```
Вопрос:
"Вас пригласили на ужин в Японии.
 Хозяин постоянно доливает вам саке. Как остановить?"

──────────────────────────────────────
COCOT:

Perception:
- Факт: доливают напиток
- Интерпретация: "Хозяин проявляет гостеприимство"

Situation:
- Я: гость в чужой стране
- Контекст: Япония (важны ритуалы вежливости)
- Проблема: не хочу больше пить, но не хочу обидеть

Norm:
1. "В Японии отказываться от еды/питья = грубость"
2. "Пустая чашка = сигнал долить"
3. "Полная чашка = 'больше не хочу'"

Решение:
"Оставить чашку полной (не допивать)"
```

**Ключ**: CoCoT **извлекает культурные нормы** из обучающих данных.

#### **Пример 3: Амбивалентная ситуация**

```
Вопрос:
"Друг спрашивает: 'Как я выгляжу?'
 Честно говоря, наряд неудачный. Что ответить?"

──────────────────────────────────────
COCOT:

Perception:
- Вижу: наряд объективно неудачен
- Эмоция друга: волнение, ожидание одобрения

Situation:
- Роль: близкий друг (не случайный знакомый)
- Контекст: перед важным событием
- Цель: поддержать, но не обманывать

Norm:
1. "Друзьям говорят правду"
2. "Перед событием не стоит разрушать уверенность"
3. "Конструктивная критика лучше резкой"

Reasoning:
"Норма 1 vs Норма 2 = конфликт
 Но Норма 3 даёт компромисс"

Решение:
"Ты выглядишь хорошо! Хотя, может,
 другой шарф подошёл бы ещё лучше?"
```

### 6.4 Применение в реальных задачах

#### **Применение 1: Customer Support AI**

**Задача**: Обработать жалобу клиента.

```
Клиент: "Ваш продукт — отстой! Требую возврат денег!"

Обычный AI:
"Извините, вот инструкция по возврату"

CoCoT AI:
──────────────────────
Perception:
"Клиент зол, использует грубые слова"

Situation:
"Клиент расстроен опытом использования
 Вероятно, ожидания не оправдались
 Роль AI: первая линия поддержки"

Norm:
"В конфликтах сначала снизить эмоции
 Показать эмпатию перед решением проблемы"

Ответ:
"Понимаю ваше разочарование, это действительно
 неприятно. Давайте разберёмся, что пошло не так,
 чтобы найти лучшее решение для вас."
```

**Результат**: Удовлетворённость клиентов +15% (реальные данные компании).

#### **Применение 2: Автономные автомобили**

**Задача**: Машина на узкой дороге, навстречу пешеход.

```
Ситуация:
- Скорость: 40 км/ч
- Дистанция до пешехода: 50 м
- Обочина справа (можно съехать)

Обычный AI:
"Препятствие → тормозить"

CoCoT AI:
──────────────────────
Perception:
"Пешеход переходит дорогу медленно
 Вероятно, пожилой человек"

Situation:
"Я: автономный автомобиль
 Пассажиры: 2 взрослых
 Ответственность: безопасность всех"

Norm:
"Жизнь людей > удобство пассажиров
 Пешеходы имеют приоритет
 Резкие манёвры опасны"

Решение:
"Плавно снизить скорость до 20 км/ч
 Готовность съехать на обочину
 Не сигналить (может испугать пешехода)"
```

#### **Применение 3: Медицинский AI-ассистент**

```
Пациент: "У меня болит живот, сильно. Что делать?"

Обычный AI:
"Возможные причины: гастрит, язва, аппендицит..."

CoCoT AI:
──────────────────────
Perception:
"Боль описана как 'сильная'
 Тон тревожный"

Situation:
"Пациент обращается удалённо (не в больнице)
 Нет медицинской истории
 Я: AI, не врач"

Norm:
"При острой боли — рекомендовать врача
 AI не должен ставить диагнозы
 Но может оценить срочность"

Решение:
"Сильная боль в животе может быть серьёзной.
 Рекомендую срочно обратиться к врачу или
 в скорую помощь. Не принимайте обезболивающие
 до осмотра — это может смазать картину.

 Если боль усиливается или появилась температура —
 вызывайте скорую немедленно."
```

---

## 7. СРАВНЕНИЕ АРХИТЕКТУР

### 7.1 Таблица: SOAR vs ACT-R vs LLM-based

| **Характеристика**     | **SOAR**                     | **ACT-R**                    | **LLM-based (2024-25)**       |
|------------------------|------------------------------|------------------------------|-------------------------------|
| **Год создания**       | 1983                         | 1993                         | 2020-2025                     |
| **Основа**             | Problem space search         | Activation + Production rules| Neural networks (Transformers)|
| **Память**             | Working + Procedural         | Declarative + Procedural     | Context window + Vector DB    |
| **Обучение**           | Chunking                     | Strengthening + Compilation  | Fine-tuning + In-context      |
| **Планирование**       | ⭐⭐⭐⭐⭐ (центральное)    | ⭐⭐⭐ (через subgoals)       | ⭐⭐⭐⭐ (CoT, ReAct)          |
| **Рассуждения**        | ⭐⭐⭐⭐ (логические)        | ⭐⭐⭐⭐⭐ (психологически точные)| ⭐⭐⭐ (вероятностные)       |
| **Языковые способности**| ⭐ (нужны модули)           | ⭐ (нужны модули)            | ⭐⭐⭐⭐⭐ (native)            |
| **Восприятие**         | ⭐⭐ (символьное)            | ⭐⭐ (символьное)             | ⭐⭐⭐⭐ (multimodal)          |
| **Объяснимость**       | ⭐⭐⭐⭐⭐ (видны правила)   | ⭐⭐⭐⭐⭐ (видны правила)    | ⭐⭐ (чёрный ящик)            |
| **Гибкость**           | ⭐⭐ (требует программирование)| ⭐⭐ (требует программирование)| ⭐⭐⭐⭐⭐ (natural language) |
| **Масштаб знаний**     | ⭐⭐ (сотни правил)          | ⭐⭐⭐ (тысячи chunks)        | ⭐⭐⭐⭐⭐ (обучение на интернете)|
| **Точность (узкие задачи)**| ⭐⭐⭐⭐⭐             | ⭐⭐⭐⭐⭐                    | ⭐⭐⭐ (hallucinations)       |
| **Точность (общие задачи)**| ⭐⭐                  | ⭐⭐                         | ⭐⭐⭐⭐⭐                     |
| **Скорость**           | ⭐⭐⭐⭐ (~50 cycles/sec)    | ⭐⭐⭐⭐ (реальное время)     | ⭐⭐⭐ (зависит от API)       |
| **Стоимость**          | Бесплатно (open-source)      | Бесплатно (open-source)      | 💲💲💲 (API calls)          |

### 7.2 Когда использовать каждую

#### **Используйте SOAR когда:**

✅ **Нужна адаптивность и планирование**
- Робот в динамичной среде
- Игровой AI с сложными стратегиями
- Автономные системы (дроны, автомобили)

✅ **Важна объяснимость**
- Медицинские системы (нужно объяснить диагноз)
- Военные приложения (ответственность за решения)

✅ **Задача хорошо формализована**
- Логистическое планирование
- Управление ресурсами

**Примеры проектов**:
- Управление авиацией (TacAir-SOAR)
- Игровые NPC (Unreal Tournament)
- Обучающие системы (моделирование принятия решений)

#### **Используйте ACT-R когда:**

✅ **Моделируете человеческое поведение**
- Психологические исследования
- Обучающие системы (нужно предсказать ошибки студентов)
- UI/UX тестирование (как пользователь будет взаимодействовать)

✅ **Важна психологическая точность**
- Когнитивная реабилитация
- Исследования памяти, внимания

✅ **Нужны временные предсказания**
- "Сколько времени займёт задача?"
- Оптимизация интерфейсов по времени реакции

**Примеры проектов**:
- Adaptive tutoring systems
- Моделирование обучения иностранным языкам
- Исследования multi-tasking

#### **Используйте LLM-based когда:**

✅ **Нужна языковая гибкость**
- Чат-боты, ассистенты
- Обработка естественного языка
- Креативные задачи (генерация контента)

✅ **Широкая domain coverage**
- Общие помощники (типа ChatGPT)
- Мультимодальные приложения (текст+изображения)

✅ **Быстрое прототипирование**
- Можно описать задачу словами, не программируя
- Итерации за часы, а не месяцы

✅ **Огромный масштаб знаний**
- Вопросо-ответные системы
- Суммаризация, перевод, анализ

**Примеры проектов**:
- Virtual assistants (Siri, Alexa с LLM)
- Code generation (GitHub Copilot, Cursor)
- Content creation (копирайтинг, дизайн)

### 7.3 Гибридные подходы (LLM + SOAR идеи)

**Тренд 2025**: Объединение сильных сторон обеих парадигм.

#### **Подход 1: LLM как "интуиция", SOAR как "рассуждения"**

```
┌──────────────────────────────┐
│   LLM (Fast Thinking)        │
│   "Быстрая генерация идей"   │
└──────────┬───────────────────┘
           │
           ▼
┌──────────────────────────────┐
│   SOAR-like Verifier         │
│   "Проверка логики"          │
└──────────┬───────────────────┘
           │
           ▼
      Финальное решение
```

**Пример**:
```
Задача: "Спланировать маршрут доставки для 10 заказов"

LLM генерирует:
"Маршрут: A → B → C → D → E → F → G → H → I → J"

SOAR-verifier проверяет:
- Нарушений ограничений: 0
- Общее расстояние: 47 км
- Время: 3.2 часа
✅ Валидно

Альтернатива LLM:
"Маршрут: A → D → B → ..."

SOAR-verifier:
- Нарушение: заказ D требует A сначала
❌ Невалидно → Запросить новый вариант
```

#### **Подход 2: LLM для восприятия, ACT-R для памяти**

```
User input (текст/изображение)
    ↓
LLM обрабатывает → "Пользователь спросил про погоду"
    ↓
ACT-R память:
  - Извлечь: "Вчера он спрашивал про Лондон"
  - Связать: "Вероятно, про погоду в Лондоне"
    ↓
LLM генерирует ответ:
  "В Лондоне сейчас 15°C, облачно"
```

**Преимущество**: LLM понимает язык, ACT-R помнит контекст.

#### **Подход 3: Neuro-Symbolic Architecture**

```
┌─────────────────────────────────────┐
│  SYMBOLIC LAYER (SOAR/ACT-R)        │
│  - Логические правила               │
│  - Планирование                     │
│  - Верификация                      │
└────────────┬────────────────────────┘
             │ Interface
┌────────────▼────────────────────────┐
│  NEURAL LAYER (LLM)                 │
│  - Восприятие (vision, language)    │
│  - Генерация гипотез                │
│  - Аппроксимация функций            │
└─────────────────────────────────────┘
```

**Пример системы**:
- **Symbolic**: Знает правила дорожного движения (формально)
- **Neural**: Распознаёт дорожные знаки, пешеходов (нейросеть)
- **Интеграция**: Нейросеть видит "красный свет" → символьное правило "остановиться"

**Реальные проекты**:
- **NeSy (Neuro-Symbolic AI)** — MIT, IBM
- **AlphaGeometry** (Google DeepMind, 2024) — геометрия через символьный solver + LLM
- **Wolfram + GPT** — калькуляторы + языковые модели

---

## 8. БУДУЩЕЕ КОГНИТИВНЫХ АРХИТЕКТУР

### 8.1 Интеграция символьного AI и нейросетей

**Проблема**: Символьные системы точны, но хрупки. Нейросети гибки, но непредсказуемы.

**Решение**: **Гибридные архитектуры**, где каждый компонент делает то, что у него лучше получается.

```
┌────────────────────────────────────────┐
│       БУДУЩАЯ АРХИТЕКТУРА (2025-2030)  │
├────────────────────────────────────────┤
│                                        │
│  ┌──────────────┐   ┌──────────────┐  │
│  │   NEURAL     │   │  SYMBOLIC    │  │
│  │   (LLM)      │◄─►│  (Rules)     │  │
│  └──────┬───────┘   └───────┬──────┘  │
│         │                   │          │
│         └─────────┬─────────┘          │
│                   │                    │
│         ┌─────────▼──────────┐         │
│         │   ORCHESTRATOR     │         │
│         │  (Координатор)     │         │
│         └─────────┬──────────┘         │
│                   │                    │
│         ┌─────────▼──────────┐         │
│         │   MEMORY SYSTEM    │         │
│         │  (Unified Memory)  │         │
│         └─────────┬──────────┘         │
│                   │                    │
│         ┌─────────▼──────────┐         │
│         │   META-LEARNER     │         │
│         │ (Улучшение себя)   │         │
│         └────────────────────┘         │
│                                        │
└────────────────────────────────────────┘
```

**Ключевые идеи**:

1. **Модульность**: Каждый компонент — специалист
2. **Переключение**: Система выбирает нейросеть или символьное рассуждение
3. **Обратная связь**: Символьный слой корректирует hallucinations нейросети

**Пример работы**:
```
Задача: "Решить математическую задачу из текста"

Шаг 1 (Neural):
  LLM читает: "У Джона было 5 яблок, он купил ещё 3..."
  Извлекает: Числа 5, 3; Операция: сложение

Шаг 2 (Symbolic):
  Формальный solver: 5 + 3 = 8

Шаг 3 (Neural):
  LLM формулирует ответ: "У Джона стало 8 яблок"

Шаг 4 (Verification):
  Symbolic проверяет: 8 соответствует 5+3 ✅
```

### 8.2 Neuro-Symbolic AI

**Определение**: Архитектура, где нейросети и символьные системы **взаимодействуют на глубоком уровне**, а не просто последовательно.

#### **Подход 1: Neural-Symbolic Integration (NSI)**

**Идея**: Нейросеть учится использовать символьные операции как "инструменты".

```
Input: "Если A > B и B > C, что можно сказать про A и C?"

Neural Network:
  ↓ (Распознаёт паттерн "транзитивность")

Вызывает Symbolic Rule:
  Rule: transitive(A, B, C) → A > C

Output: "A > C"
```

**Преимущество**: Нейросеть не "угадывает" логику, а применяет **гарантированно верное** правило.

#### **Подход 2: Differentiable Logic**

**Идея**: Сделать символьные операции дифференцируемыми, чтобы нейросеть могла обучаться через них.

```
Обычная логика:
  AND(True, False) = False (дискретно)

Differentiable logic:
  AND(0.9, 0.2) = 0.18 (непрерывно)

Можно использовать gradient descent!
```

**Применение**: Нейросеть учится логическим правилам **автоматически**.

#### **Подход 3: Concept Learning**

**Идея**: Нейросеть извлекает **символьные концепции** из данных.

```
Нейросеть видит примеры:
  🐶 (собака), 🐕 (собака), 🦴 (кость)

Извлекает символ:
  IS_DOG(x) ← нейросеть(x) > 0.9

Создаёт правило:
  IF IS_DOG(x) AND near(x, bone) THEN play(x, bone)
```

**Результат**: Система создаёт **объяснимые правила** из неструктурированных данных.

### 8.3 Прогноз на 2025-2030

#### **Предсказание 1: Персонализированные когнитивные архитектуры**

**Сейчас**: Один LLM для всех пользователей.

**2025-2030**: Каждый пользователь получает **адаптированную архитектуру**.

```
User A:
  - Предпочитает детальные объяснения
  → Архитектура с усиленным Reasoning module

User B:
  - Нужны быстрые ответы
  → Архитектура с кэшированием и сокращённым CoT
```

**Механизм**: Meta-learning (обучение на паттернах взаимодействия).

#### **Предсказание 2: Lifelong Learning Agents**

**Сейчас**: Агенты "забывают" после сессии.

**2025-2030**: Агенты **непрерывно обучаются** и помнят всю историю.

```
День 1: User обучает агента: "Я предпочитаю кофе утром"
  ↓ [Сохранено в Long-term Memory]

Месяц спустя:
Agent: "Доброе утро! Как обычно, кофе?"
```

**Технологии**:
- Continual learning (обучение без забывания)
- Episodic memory (автобиографическая память)
- Neural-symbolic knowledge graphs

#### **Предсказание 3: Emotionally Intelligent Architectures**

**Сейчас**: Агенты не понимают эмоций по-настоящему.

**2025-2030**: Интеграция **эмоциональных модулей** (как миндалина в мозге).

```
┌──────────────────────────────┐
│   COGNITIVE ARCHITECTURE     │
├──────────────────────────────┤
│ Perception → Emotion Module  │
│                ↓              │
│         ┌──────┴─────┐       │
│         │ Valence:   │       │
│         │ +0.8 (joy) │       │
│         │ Arousal:   │       │
│         │ +0.6 (high)│       │
│         └──────┬─────┘       │
│                ↓              │
│        Влияет на Planning    │
│     (приоритет = снизить      │
│      негативные эмоции)       │
└──────────────────────────────┘
```

**Применение**:
- Терапевтические боты (детектируют депрессию)
- Companion AI (эмоциональная поддержка)
- Customer service (распознавание фрустрации)

#### **Предсказание 4: Multi-Agent Cognitive Swarms**

**Сейчас**: Один агент делает всё.

**2025-2030**: **Рои специализированных агентов**, координирующихся как пчёлы.

```
Задача: "Написать научную статью"

Рой из 10 агентов:
  - Agent 1-3: Researcher (собирают данные)
  - Agent 4-5: Writer (пишут разделы)
  - Agent 6-7: Critic (проверяют логику)
  - Agent 8: Coordinator (управляет процессом)
  - Agent 9: Memory (общая база знаний)
  - Agent 10: Meta-learner (улучшает стратегию)

Итог: Статья за 2 часа вместо недели
```

**Технологии**:
- Emergent coordination (самоорганизация)
- Consensus mechanisms (голосование агентов)
- Distributed cognition

#### **Предсказание 5: Hybrid Human-AI Cognition**

**Сейчас**: Человек и AI работают отдельно.

**2025-2030**: **Бесшовная интеграция** через нейроинтерфейсы.

```
Человек думает: "Как решить уравнение X?"
  ↓ [EEG/BCI фиксирует намерение]

AI архитектура:
  - Распознаёт намерение
  - Извлекает релевантные знания
  - Предлагает решение
  ↓ [Отображается в AR/VR или внутренний диалог]

Человек: "Ага, понял!" (мгновенно)
```

**Области применения**:
- Образование (augmented learning)
- Медицина (AI-ассистированная хирургия)
- Креативность (co-creation музыки, искусства)

#### **Предсказание 6: Self-Evolving Architectures**

**Сейчас**: Архитектуру проектируют люди.

**2025-2030**: Архитектуры **сами себя модифицируют**.

```
Архитектура обнаруживает:
"Я часто делаю ошибки в математике"
  ↓
Анализирует:
"Проблема в Reasoning module → нужен Symbolic verifier"
  ↓
Автоматически добавляет:
  New Module: Math_Solver (Wolfram Alpha API)
  ↓
Тестирует:
  Точность выросла с 82% до 97% ✅
  ↓
Сохраняет изменение в архитектуре
```

**Механизм**: Neural Architecture Search (NAS) + Meta-learning.

---

## ЗАКЛЮЧЕНИЕ

### Чек-лист понимания главы

Проверьте себя — вы должны уметь объяснить:

✅ **Что такое когнитивная архитектура** (не просто "код агента", а принципы организации интеллекта)

✅ **Problem Space Hypothesis** (интеллект = поиск в пространстве состояний)

✅ **SOAR**:
   - Working memory, Procedural memory
   - Decision cycle
   - Chunking (обучение)
   - Impasse resolution

✅ **ACT-R**:
   - Declarative vs Procedural knowledge
   - Production system
   - Моделирование забывания и обучения

✅ **LLM-based архитектуры**:
   - Scaffolding (LLM + модули)
   - 4 компонента: Perception, Memory, Planning, Reasoning
   - Примеры: AutoGPT, MetaGPT, BabyAGI

✅ **CoCoT**:
   - 3 стадии: Perception → Situation → Norm
   - Почему точнее обычного CoT

✅ **Сравнение**:
   - Когда использовать SOAR, ACT-R, LLM-based
   - Гибридные подходы

✅ **Будущее**:
   - Neuro-symbolic AI
   - Lifelong learning
   - Emotional intelligence
   - Multi-agent swarms

---

### Ключевые выводы

1. **Когнитивная архитектура ≠ Код агента**
   - Это фундаментальные принципы организации интеллекта

2. **Классические архитектуры (SOAR, ACT-R) актуальны**
   - Объяснимость, точность, психологическая валидность

3. **LLM-based архитектуры революционны**
   - Гибкость, язык, масштаб знаний

4. **Будущее — гибриды**
   - Нейросети (гибкость) + Символы (логика) = Robust AI

5. **CoCoT показывает путь**
   - Добавление "когнитивных стадий" улучшает reasoning

---

### Дальнейшее изучение

**Книги**:
- "Unified Theories of Cognition" — Allen Newell
- "The Atomic Components of Thought" — John Anderson (ACT-R)
- "Artificial Intelligence: A Modern Approach" — Russell & Norvig (глава про agents)

**Статьи** (2024-2025):
- "Cognitive Architectures for Language Agents" (arxiv.org)
- "CoCoT: Cognitive Chain-of-Thought" (January 2025)
- "LLM-Modulo Framework" (Stanford, 2024)

**Практика**:
- Установить SOAR: soartech.com
- Экспериментировать с ACT-R: act-r.psy.cmu.edu
- Создать LLM-агента: langchain, autogen

---

## 🧠 ТЕОРИЯ: Когнитивные архитектуры в агентных системах

### Что такое когнитивная архитектура?

**Когнитивная архитектура** — это комплексная вычислительная модель, имитирующая структуру и процессы человеческого познания. Это не просто алгоритм или набор правил, а целостная система, определяющая:

- **Представление знаний** — как агент хранит информацию о мире
- **Механизмы обработки** — как агент рассуждает и принимает решения
- **Обучение и память** — как агент накапливает опыт
- **Восприятие и действие** — как агент взаимодействует со средой

**Ключевое отличие** от обычных AI систем: когнитивная архитектура стремится к **универсальности** — способности решать широкий класс задач с единой базовой структурой, подобно человеческому разуму.

---

### Основные когнитивные архитектуры

#### 1. **SOAR (State, Operator And Result)**

**Философия**: Вся когнитивная деятельность — это поиск в пространстве проблем.

**Ключевые компоненты**:
- **Рабочая память** — текущее состояние задачи
- **Долговременная память**:
  - *Процедурная* (правила если-то)
  - *Декларативная* (факты)
  - *Эпизодическая* (опыт)
- **Механизм решения проблем**:
  - Применение операторов для изменения состояния
  - При отсутствии знаний — создание подцелей (impasse)
  - Chunking — автоматическое обучение из решений

**Цикл принятия решений**:
```
1. Предложение (Propose) — генерация возможных операторов
2. Сравнение (Compare) — оценка альтернатив
3. Применение (Apply) — выполнение выбранного оператора
4. Обучение (Learn) — создание chunks при успехе
```

**Применение**:
- Робототехника (автономная навигация)
- Военные симуляторы (тактическое планирование)
- Интеллектуальные обучающие системы
- Игровые AI (сложное поведение NPC)

**Пример кода концепции**:
```python
class SOARAgent:
    def __init__(self):
        self.working_memory = {}  # Текущее состояние
        self.procedural_memory = []  # Правила
        self.episodic_memory = []  # История

    def decide(self, state):
        # Фаза предложения: найти применимые операторы
        operators = self.propose_operators(state)

        if not operators:
            # Impasse: создать подцель
            return self.create_subgoal(state)

        # Фаза сравнения: выбрать лучший оператор
        best_op = self.compare_operators(operators)

        # Фаза применения
        new_state = self.apply_operator(best_op, state)

        # Обучение: создать chunk
        self.learn_chunk(state, best_op, new_state)

        return new_state
```

---

#### 2. **ACT-R (Adaptive Control of Thought—Rational)**

**Философия**: Познание — это взаимодействие независимых модулей через центральную процедурную систему.

**Архитектура модулей**:
- **Декларативный модуль** — факты и концепции (chunks)
- **Процедурный модуль** — правила продукций (если-то)
- **Перцептивные модули** — визуальный, аудиальный
- **Моторный модуль** — выполнение действий
- **Модуль целей** — управление задачами

**Ключевые механизмы**:

1. **Активация памяти**:
   - Базовая активация (частота использования)
   - Распространяющаяся активация (ассоциации)
   - Шум (стохастичность)

```python
activation = base_activation + spreading_activation + noise
retrieval_time = F * e^(-activation)  # Latency equation
```

2. **Utility learning** (обучение полезности):
   - Каждое правило имеет ожидаемую награду
   - Обновляется через reinforcement learning
   - Выбирается правило с максимальной утилитой

3. **Субсимвольный уровень**:
   - Математические модели времени и вероятностей
   - Предсказание RT (reaction time) с точностью до миллисекунд

**Применение**:
- Когнитивное моделирование (HCI исследования)
- Интеллектуальные тьюторы (Cognitive Tutor)
- Предсказание ошибок пилотов
- Моделирование процессов чтения

**Пример структуры**:
```lisp
; ACT-R production rule
(p retrieve-fact
   =goal>
     isa question
     query =q
   ?retrieval>
     state free
==>
   +retrieval>
     isa fact
     question =q
   =goal>
     state retrieving
)
```

---

#### 3. **BDI (Belief-Desire-Intention)**

**Философия**: Агент — это рациональный актор с ментальными состояниями.

**Три компонента**:
- **Beliefs (убеждения)** — знания агента о мире
- **Desires (желания)** — возможные цели
- **Intentions (намерения)** — выбранные цели для достижения

**Цикл BDI**:
```
1. Обновление Beliefs (восприятие среды)
2. Генерация опций (возможные Desires)
3. Фильтрация (выбор намерений из желаний)
4. Планирование (как достичь Intentions)
5. Выполнение (исполнение плана)
6. Возврат к шагу 1
```

**Формальная логика**:
```
Bel(φ)  — агент верит, что φ истинно
Des(φ)  — агент желает, чтобы φ было истинно
Int(φ)  — агент намерен сделать φ истинным

Аксиомы:
- Int(φ) → Des(φ)  (намерения — подмножество желаний)
- Int(φ) → Bel(possible(φ))  (намерения реалистичны)
```

**Применение**:
- Автономные роботы (Mars rovers)
- Управление воздушным движением
- Умные дома (распределенное управление)
- Мультиагентные симуляции (экономика, социология)

**Пример реализации**:
```python
class BDIAgent:
    def __init__(self):
        self.beliefs = KnowledgeBase()
        self.desires = []
        self.intentions = []
        self.plans = {}

    def sense_environment(self, percepts):
        # Обновление убеждений
        for percept in percepts:
            self.beliefs.update(percept)

    def generate_options(self):
        # Генерация желаний на основе убеждений
        new_desires = []
        for goal_pattern in self.goal_templates:
            if goal_pattern.matches(self.beliefs):
                new_desires.append(goal_pattern.instantiate())
        return new_desires

    def filter_intentions(self, desires):
        # Выбор намерений (deliberation)
        intentions = []
        for desire in desires:
            if self.is_achievable(desire) and self.is_compatible(desire):
                intentions.append(desire)
        return intentions

    def execute_cycle(self):
        # Основной цикл BDI
        percepts = self.perceive()
        self.sense_environment(percepts)

        options = self.generate_options()
        self.intentions = self.filter_intentions(options)

        for intention in self.intentions:
            plan = self.plans.get(intention)
            if plan:
                self.execute_plan(plan)
```

---

### Сравнение подходов: SOAR vs ACT-R vs BDI

| Критерий | SOAR | ACT-R | BDI |
|----------|------|-------|-----|
| **Фокус** | Универсальное решение проблем | Моделирование человеческого познания | Рациональное действие |
| **Основной механизм** | Поиск в пространстве задач | Сопоставление правил с активацией | Рассуждение о целях |
| **Обучение** | Chunking (автоматическое) | Utility + activation tuning | Обучение планам |
| **Память** | 3 типа (процедурная, декларативная, эпизодическая) | Chunks + productions | Базы убеждений |
| **Время реакции** | Не моделируется | Точные предсказания RT | Не моделируется |
| **Применимость** | Робототехника, игры | Когнитивные исследования, HCI | Мультиагентные системы |
| **Сложность имплементации** | Средняя | Высокая (субсимвольные расчеты) | Средняя |
| **Стандарты** | Soar 9.6+ | ACT-R 7.x | AgentSpeak(L), Jason |

---

### Применение в современных AI агентах

#### LLM + когнитивные архитектуры

**Проблемы чистых LLM**:
- Отсутствие явной памяти
- Непредсказуемое рассуждение
- Сложность с долгосрочным планированием
- Нет обучения на опыте в реальном времени

**Гибридные подходы** (2024-2025):

1. **LLM-SOAR**:
   - LLM генерирует операторы
   - SOAR выбирает и применяет их
   - Chunking создает специализированные правила

   ```python
   class LLM_SOAR:
       def propose_operators(self, state):
           prompt = f"Given state: {state}, suggest possible actions:"
           llm_suggestions = self.llm.generate(prompt)
           return self.parse_to_soar_operators(llm_suggestions)
   ```

2. **ACT-R + Language Models**:
   - LLM как декларативная память
   - ACT-R управляет извлечением
   - Активация определяет, что запрашивать у LLM

   ```python
   if activation(chunk) > threshold:
       return internal_memory.retrieve(chunk)
   else:
       return llm.query(chunk_to_prompt(chunk))
   ```

3. **BDI-LLM Agents**:
   - LLM для генерации планов
   - BDI для управления целями и выполнением
   - Ментальные состояния как промпты

   ```python
   desires = llm.generate(f"Given beliefs: {beliefs}, what are possible goals?")
   plans = llm.generate(f"How to achieve intention: {intention}?")
   ```

#### Примеры систем (2024-2025)

**Cognitive Kernel** (Microsoft Research):
- Интеграция SOAR-подобной архитектуры с GPT-4
- Автоматическое создание skills (chunks)
- Используется в Copilot Pro

**ReAct + Memory** (Google DeepMind):
- Reasoning + Acting в LLM
- Внешняя эпизодическая память (векторная БД)
- BDI-подобный цикл восприятие-рассуждение-действие

**AutoGPT с когнитивной архитектурой**:
- Working memory (контекстное окно)
- Long-term memory (Pinecone, Weaviate)
- Self-reflection (метакогнитивные правила)

---

### Будущее: Нейро-символьные когнитивные архитектуры

**Тренд 2025+**: Объединение:
- **Символьных** систем (SOAR, ACT-R, BDI) — для структурированного рассуждения
- **Нейронных** сетей (LLM, RL) — для обучения и обобщения

**Примеры направлений**:
- **Differentiable reasoning** — сделать SOAR обучаемым через градиенты
- **Neural production systems** — правила как нейронные модули
- **Grounded language** — связать LLM с сенсомоторным опытом (embodied AI)

**Гипотеза**: Истинный AGI потребует когнитивной архитектуры, сочетающей:
- Быструю адаптацию (нейронные сети)
- Структурированное знание (символьные системы)
- Многоуровневую память (SOAR/ACT-R)
- Целенаправленное поведение (BDI)

---

## ❓ ВОПРОСЫ ДЛЯ САМОПРОВЕРКИ

### 1. Что такое когнитивная архитектура и чем она отличается от обычного AI алгоритма?

<details>
<summary>Развернутый ответ</summary>

**Когнитивная архитектура** — это комплексная вычислительная модель, имитирующая общие механизмы человеческого познания (память, внимание, обучение, рассуждение) и способная решать широкий класс задач с единой базовой структурой.

**Ключевые отличия от обычных AI алгоритмов**:

1. **Универсальность vs специализация**:
   - Алгоритм: решает конкретную задачу (классификация, поиск пути)
   - Архитектура: общая основа для любых когнитивных задач

2. **Множественность компонентов**:
   - Алгоритм: обычно один процесс (backpropagation, A*)
   - Архитектура: система модулей (память, восприятие, моторика, рассуждение)

3. **Обучение на протяжении жизни**:
   - Алгоритм: тренируется на датасете, затем фиксируется
   - Архитектура: постоянно накапливает опыт (chunking в SOAR, utility learning в ACT-R)

4. **Биологическая достоверность**:
   - Алгоритм: эффективность — главный критерий
   - Архитектура: стремится моделировать реальные когнитивные процессы (например, ACT-R предсказывает RT с точностью до миллисекунд)

**Аналогия**: Алгоритм — это *инструмент* (молоток), когнитивная архитектура — это *мастерская* с набором инструментов и методами их использования.
</details>

---

### 2. Опишите основные компоненты архитектуры SOAR. Что такое "impasse" и "chunking"?

<details>
<summary>Развернутый ответ</summary>

**Компоненты SOAR**:

1. **Рабочая память (Working Memory)** — текущее состояние задачи, воспринятые данные, активные цели
2. **Долговременная память**:
   - *Процедурная* — правила "если-то" (productions)
   - *Декларативная* — факты и знания (semantic)
   - *Эпизодическая* — история опыта (что было когда)
3. **Система принятия решений** — выбор и применение операторов

**Impasse (тупик)**:
- Ситуация, когда агент не знает, что делать (нет применимых операторов, несколько одинаково хороших вариантов, или неизвестно состояние)
- **Не ошибка**, а триггер для создания **подцели**
- Типы: *no-change* (нет прогресса), *tie* (несколько лучших), *conflict* (противоречие), *reject* (все варианты плохие)

**Пример impasse**:
```
Цель: открыть дверь
Состояние: дверь заперта
Операторы: [открыть дверь] — не применим (нужен ключ)
→ IMPASSE → Создать подцель: "найти ключ"
```

**Chunking (обучение)**:
- Когда подцель решена, SOAR автоматически создает **chunk** — новое правило, которое в будущем сразу применит найденное решение
- **Компиляция опыта** в процедурную память

**Пример chunking**:
```
Опыт: дверь заперта → найти ключ → открыть дверь
Chunk: ЕСЛИ (дверь заперта) ТО (найти ключ, затем открыть)
→ В следующий раз сразу применяется, без impasse
```

**Преимущество**: Агент становится быстрее и эффективнее через опыт.
</details>

---

### 3. Как работает механизм активации памяти в ACT-R? Почему это важно для моделирования человеческого познания?

<details>
<summary>Развернутый ответ</summary>

**Механизм активации в ACT-R**:

Каждый chunk (единица декларативной памяти) имеет уровень **активации** (A), который определяет:
- **Вероятность** извлечения из памяти
- **Скорость** извлечения (Retrieval Time)

**Формула активации**:
```
A_i = B_i + Σ W_j * S_ji + ε

Где:
- B_i — базовая активация (base-level activation)
- W_j — вес внимания к источнику j
- S_ji — сила ассоциации между источником j и chunk i
- ε — случайный шум
```

**Компоненты**:

1. **Базовая активация (B_i)**:
   ```
   B_i = ln(Σ t_j^(-d))

   t_j — время с момента j-го использования chunk
   d — decay parameter (обычно 0.5)
   ```
   - Отражает **частоту** и **недавность** использования
   - Редко используемые chunks имеют низкую B_i

2. **Распространяющаяся активация (Σ W_j * S_ji)**:
   - От источников внимания (например, текущая цель) активация "распространяется" к связанным chunks
   - Моделирует **ассоциативное мышление**
   - Пример: думая о "кофе", активируется "чашка", "утро", "кофеин"

3. **Шум (ε)**:
   - Случайная вариация (нормальное распределение)
   - Моделирует **вариабельность** человеческого поведения

**Retrieval Time (RT)**:
```
RT = F * e^(-A)

F — latency factor (обычно ~0.5)
```
- Чем выше активация, тем быстрее извлечение
- **Предсказывает реальное время реакции человека!**

**Почему это важно?**

1. **Эмпирическая точность**: ACT-R предсказывает RT с корреляцией >0.9 с экспериментальными данными
2. **Моделирование забывания**: Неиспользуемые chunks теряют активацию (закон Эббингауза)
3. **Контекстная зависимость**: Активация изменяется в зависимости от текущей ситуации
4. **Объяснение ошибок**: Низкая активация → медленное/неточное извлечение → ошибки

**Пример применения**:
```python
# Моделирование времени ответа на вопрос
chunk = {"fact": "Столица Франции", "answer": "Париж"}
base_activation = calculate_base(chunk, history)  # Как часто вспоминали?
spreading = calculate_spreading(chunk, current_goal)  # Связано с текущим контекстом?
noise = random.gauss(0, 0.25)

activation = base_activation + spreading + noise

if activation > threshold:
    RT = 0.5 * exp(-activation)  # Быстро, если высокая активация
    return chunk["answer"], RT
else:
    return "Не помню", None  # Не извлечено
```
</details>

---

### 4. В чем суть BDI архитектуры? Как соотносятся убеждения, желания и намерения?

<details>
<summary>Развернутый ответ</summary>

**BDI (Belief-Desire-Intention)** — архитектура, моделирующая агента как **рационального актора** с ментальными состояниями.

**Три компонента**:

1. **Beliefs (Убеждения)**:
   - Знания агента о текущем состоянии мира
   - Могут быть неполными или неточными
   - Обновляются через восприятие
   - Пример: "Дверь закрыта", "Батарея на 20%", "Пользователь находится в комнате"

2. **Desires (Желания)**:
   - Множество возможных целей
   - Могут быть **противоречивыми** (хочу есть торт И хочу похудеть)
   - Не обязательно достижимы одновременно
   - Пример: "Открыть дверь", "Зарядить батарею", "Помочь пользователю"

3. **Intentions (Намерения)**:
   - **Выбранные** цели, на достижение которых агент **обязуется**
   - Согласованные, достижимые, без конфликтов
   - Определяют текущие действия
   - Пример: "Сейчас иду к двери" (выбрано из желаний)

**Соотношение**:
```
Beliefs → основа для оценки реальности
         ↓
Desires → генерируются на основе убеждений и внутренних мотиваций
         ↓
Intentions → фильтрованное подмножество желаний (deliberation)
         ↓
Plans → как достичь намерений
         ↓
Actions → выполнение плана
```

**Формальная логика**:
```
1. Int(φ) → Des(φ)
   (Если я намерен φ, то я желаю φ)

2. Int(φ) → Bel(possible(φ))
   (Если я намерен φ, то я верю, что φ возможно)

3. Bel(φ) ∧ Bel(φ → ψ) → Bel(ψ)
   (Убеждения логически согласованы)
```

**Цикл BDI агента**:
```python
while True:
    # 1. Восприятие → обновление Beliefs
    new_beliefs = perceive_environment()
    beliefs.update(new_beliefs)

    # 2. Генерация Desires на основе Beliefs
    desires = generate_options(beliefs)
    # Например: Если Bel(дверь_закрыта) → Des(открыть_дверь)

    # 3. Фильтрация → выбор Intentions (deliberation)
    # Критерии: достижимость, совместимость, приоритет
    intentions = filter(desires, beliefs)

    # 4. Планирование
    plans = plan(intentions, beliefs)

    # 5. Выполнение
    execute(plans)
```

**Пример**:
```
Beliefs: {батарея: 15%, дверь_открыта: False, время: 14:00}

Desires:
- открыть_дверь (важность: 8)
- зарядить_батарею (важность: 9)
- исследовать_комнату (важность: 5)

Deliberation:
- зарядить_батарею → высокий приоритет (батарея критична)
- открыть_дверь → отложить (не критично)

Intentions: [зарядить_батарею]

Plan:
  1. Найти зарядку
  2. Подключиться
  3. Ждать до 80%
```

**Преимущества BDI**:
- Явное представление целей (не скрыто в правилах)
- Гибкость (переоценка намерений при изменении убеждений)
- Объяснимость (можно спросить "почему агент делает X?" → "потому что намерен Y")
</details>

---

### 5. Какие преимущества и недостатки имеет каждая из трех основных архитектур (SOAR, ACT-R, BDI)?

<details>
<summary>Развернутый ответ</summary>

**SOAR**

**Преимущества**:
- ✅ **Универсальность**: Решает любые задачи, представимые как поиск
- ✅ **Автоматическое обучение**: Chunking не требует дополнительной настройки
- ✅ **Множественные типы памяти**: Процедурная, декларативная, эпизодическая
- ✅ **Интеграция**: Легко добавлять новые модули (восприятие, моторику)
- ✅ **Активное сообщество**: Soar Technology, военные исследования

**Недостатки**:
- ❌ **Не моделирует время**: Нет предсказаний RT
- ❌ **Скалируемость**: Chunking может создать слишком много правил
- ❌ **Настройка**: Impasse/subgoaling требует тщательного дизайна
- ❌ **Обучение медленное**: Chunking эффективен только при повторяемых задачах

**Лучше всего для**: Робототехника, игры, автономные системы с четкими целями

---

**ACT-R**

**Преимущества**:
- ✅ **Биологическая точность**: Предсказывает RT, BOLD сигнал (fMRI)
- ✅ **Субсимвольный уровень**: Активация, шум — моделирует вариабельность
- ✅ **Модульная архитектура**: Легко изолировать перцептивные/моторные процессы
- ✅ **Научная база**: 30+ лет исследований, сотни моделей
- ✅ **Utility learning**: Адаптация к наградам (RL)

**Недостатки**:
- ❌ **Сложность реализации**: Требует знания психологии и математики
- ❌ **Узкая применимость**: Фокус на моделировании, а не на производительности
- ❌ **Медленная работа**: Субсимвольные вычисления дорогие
- ❌ **Фиксированная архитектура**: Сложно добавить новые модули

**Лучше всего для**: Когнитивное моделирование, HCI исследования, интеллектуальные тьюторы

---

**BDI**

**Преимущества**:
- ✅ **Интуитивность**: Ментальные состояния понятны разработчикам
- ✅ **Целеориентированность**: Явное управление целями и приоритетами
- ✅ **Мультиагентность**: Естественная основа для коммуникации (обмен beliefs)
- ✅ **Гибкость**: Легко пересматривать намерения при изменениях
- ✅ **Стандарты**: AgentSpeak(L), Jason — готовые платформы

**Недостатки**:
- ❌ **Нет обучения**: Изначально не предусмотрено (нужно добавлять)
- ❌ **Неопределенность**: Плохо работает с вероятностными убеждениями
- ❌ **Deliberation стоимость**: Выбор намерений может быть дорогим
- ❌ **Абстрактность**: Нет стандартной имплементации всех компонентов

**Лучше всего для**: Мультиагентные системы, умные дома, автономные роботы с четкими целями

---

**Сравнительная таблица**:

| Критерий | SOAR | ACT-R | BDI |
|----------|------|-------|-----|
| **Обучение** | 🟢 Chunking | 🟡 Utility (нужна настройка) | 🔴 Нет (добавлять вручную) |
| **Биологичность** | 🟡 Средняя | 🟢 Высокая (RT, fMRI) | 🔴 Низкая (абстрактно) |
| **Мультиагентность** | 🟡 Возможна | 🔴 Сложно | 🟢 Естественная |
| **Скорость** | 🟢 Быстрая | 🔴 Медленная | 🟢 Быстрая |
| **Объяснимость** | 🟡 Chunking сложен | 🟢 Высокая (правила) | 🟢 Очень высокая (цели) |
| **Индустрия** | 🟢 Робототехника, игры | 🟡 Наука, HCI | 🟢 IoT, промышленность |
</details>

---

### 6. Как современные LLM-агенты могут использовать принципы когнитивных архитектур? Приведите примеры.

<details>
<summary>Развернутый ответ</summary>

**Проблемы чистых LLM**:
- Отсутствие структурированной памяти (только контекстное окно)
- Непредсказуемое рассуждение (black box)
- Нет долгосрочного обучения на опыте
- Сложность с планированием (limited lookahead)

**Гибридные подходы** (LLM + когнитивные архитектуры):

---

#### 1. **LLM + SOAR: Управляемая генерация**

**Идея**: LLM генерирует операторы, SOAR выбирает и применяет их структурированно.

**Архитектура**:
```python
class LLM_SOAR_Agent:
    def __init__(self):
        self.soar = SOAR()
        self.llm = GPT4()

    def propose_operators(self, state, goal):
        # LLM генерирует кандидатов
        prompt = f"""
        Current state: {state}
        Goal: {goal}
        Suggest 3-5 possible actions (operators).
        """
        suggestions = self.llm.generate(prompt)

        # Парсинг в SOAR операторы
        operators = self.parse_to_soar(suggestions)
        return operators

    def compare_operators(self, operators):
        # SOAR оценивает через правила или LLM
        prompt = f"Rank these actions: {operators}"
        ranking = self.llm.generate(prompt)
        return self.select_best(ranking)

    def learn_chunk(self, state, operator, result):
        # Создание chunk: если подобная ситуация — сразу применять оператор
        self.soar.add_production(
            condition=f"state matches {state}",
            action=f"apply {operator}"
        )
```

**Пример**:
```
Задача: "Написать функцию сортировки"

SOAR impasse: Не знаю, какой алгоритм использовать
→ LLM генерирует: [quicksort, mergesort, bubblesort]
→ SOAR выбирает: quicksort (правило: для больших массивов)
→ LLM генерирует код
→ SOAR создает chunk: для сортировки → сначала проверь размер → quicksort
```

**Преимущества**:
- Структурированное решение проблем
- Обучение на опыте (chunking)
- Объяснимость (SOAR трейс)

---

#### 2. **LLM + ACT-R: Управляемое извлечение знаний**

**Идея**: ACT-R управляет, **когда** и **что** запрашивать у LLM на основе активации.

**Архитектура**:
```python
class ACT_R_LLM:
    def __init__(self):
        self.internal_memory = {}  # Chunks с активацией
        self.llm = GPT4()
        self.threshold = 2.0  # Порог извлечения

    def retrieve(self, query):
        # Вычислить активацию internal chunks
        activation = self.calculate_activation(query)

        if activation > self.threshold:
            # Быстро извлечь из internal memory
            return self.internal_memory[query]
        else:
            # Запросить LLM (дорого, но точно)
            result = self.llm.query(query)

            # Сохранить в память с базовой активацией
            self.internal_memory[query] = result
            self.set_activation(query, base=3.0)  # Свежее = высокая активация

            return result

    def calculate_activation(self, query):
        # ACT-R формула
        base = self.base_activation(query)
        spreading = self.spreading_activation(query)
        noise = random.gauss(0, 0.25)
        return base + spreading + noise
```

**Пример**:
```
Вопрос: "Столица Франции?"

ACT-R:
- Проверка internal memory: activation("Париж | Франция") = 4.5 (высокая)
- → Быстрый ответ: "Париж" (без LLM)

Вопрос: "Столица Буркина-Фасо?"

ACT-R:
- Проверка internal memory: activation = 0.5 (низкая, редко вспоминали)
- → Запрос LLM: "Уагадугу"
- → Сохранить: activation = 3.0 (теперь будет доступно быстро)
```

**Преимущества**:
- Оптимизация запросов к LLM (только когда нужно)
- Моделирование человеческой памяти (частое = быстрое)
- Обучение через активацию

---

#### 3. **LLM + BDI: Рациональное планирование**

**Идея**: LLM генерирует планы, BDI управляет целями и выполнением.

**Архитектура**:
```python
class BDI_LLM_Agent:
    def __init__(self):
        self.beliefs = {}
        self.desires = []
        self.intentions = []
        self.llm = GPT4()

    def sense_environment(self, percepts):
        self.beliefs.update(percepts)

    def generate_desires(self):
        # LLM генерирует возможные цели
        prompt = f"""
        Current beliefs: {self.beliefs}
        What are possible goals for this agent?
        """
        goals = self.llm.generate(prompt)
        return self.parse_goals(goals)

    def filter_intentions(self, desires):
        # LLM оценивает достижимость и приоритеты
        prompt = f"""
        Beliefs: {self.beliefs}
        Desires: {desires}
        Select achievable and compatible intentions.
        """
        intentions = self.llm.generate(prompt)
        return self.parse_intentions(intentions)

    def plan(self, intention):
        # LLM создает план
        prompt = f"""
        Goal: {intention}
        Current state: {self.beliefs}
        Generate a step-by-step plan.
        """
        plan = self.llm.generate(prompt)
        return self.parse_plan(plan)
```

**Пример**:
```
Beliefs: {дверь: закрыта, ключ: на столе, время: утро}

LLM генерирует Desires:
- выйти_из_дома
- позавтракать
- проверить_почту

BDI фильтрация:
- выйти_из_дома: achievable (ключ доступен), приоритет: высокий
→ Intention: [выйти_из_дома]

LLM генерирует план:
1. Взять ключ со стола
2. Подойти к двери
3. Вставить ключ
4. Открыть дверь
5. Выйти

BDI выполняет план с мониторингом (если что-то меняется → пересмотр)
```

**Преимущества**:
- Явное управление целями
- Гибкость (пересмотр при изменениях)
- Объяснимость ("я делаю X, потому что намерен Y")

---

#### 4. **Реальные системы (2024-2025)**

**Microsoft Copilot Pro** (Cognitive Kernel):
- SOAR-подобная архитектура
- Skills = chunks (обучение из опыта)
- LLM для генерации кода, SOAR для управления

**AutoGPT + Memory**:
- Working memory: контекстное окно
- Long-term memory: векторная БД (Pinecone)
- Эпизодическая память: история действий
- BDI-подобный цикл: восприятие → цели → планирование

**Google DeepMind ReAct**:
- Reasoning + Acting (цикл BDI)
- LLM генерирует рассуждения и действия
- Внешние tools = расширение beliefs

---

**Вывод**: Когнитивные архитектуры дают LLM **структуру**, **память**, **обучение** и **объяснимость**.
</details>

---

### 7. Почему будущее AI может потребовать нейро-символьных когнитивных архитектур? Какие проблемы они решают?

<details>
<summary>Развернутый ответ</summary>

**Проблемы чисто нейронных систем (LLM, deep learning)**:

1. **Отсутствие структурированного рассуждения**:
   - LLM хороши в pattern matching, но плохи в логике (например, "если A и B, то C" — могут ошибиться)
   - Нет явных правил вывода

2. **Катастрофическое забывание**:
   - Обучение на новых данных стирает старые знания
   - Нельзя постоянно обучаться (как человек)

3. **Объяснимость (black box)**:
   - Невозможно понять, *почему* LLM дал ответ
   - Важно для медицины, финансов, права

4. **Неэффективность данных**:
   - Нужны миллионы примеров, человек учится с нескольких

5. **Отсутствие каузального мышления**:
   - LLM находит корреляции, но не понимает причинность

---

**Проблемы чисто символьных систем (SOAR, ACT-R, BDI)**:

1. **Хрупкость (brittleness)**:
   - Работают только в четко определенных доменах
   - Если правило не предусмотрено — система беспомощна

2. **Отсутствие обобщения**:
   - Не могут обобщать из малого числа примеров (как нейронные сети)

3. **Создание правил вручную**:
   - Требуется эксперт для написания тысяч правил
   - Дорого и медленно

4. **Плохо с сенсомоторными данными**:
   - Работают с символами, а не с изображениями/звуками

---

**Нейро-символьные системы: объединение сильных сторон**

**Идея**: Комбинировать:
- **Нейронные сети** (обучение, обобщение, восприятие)
- **Символьные системы** (логика, структура, объяснимость)

**Примеры подходов**:

#### 1. **Neural Module Networks (NMN)**
- Нейронные сети собираются динамически по символьной программе
- Пример: вопрос "Сколько синих объектов?" → программа:
  ```
  filter(color=blue) → count()
  ```
- Каждый модуль — нейронная сеть, структура — символьная

#### 2. **Differentiable Neural Computers (DNC)**
- Нейронная сеть + внешняя память с адресацией
- Может обучаться алгоритмам (сортировка, поиск пути)
- Комбинирует нейронное обучение с символьными операциями

#### 3. **Logic Tensor Networks (LTN)**
- Логические формулы интегрированы в нейронную сеть
- Можно задавать правила (ontologies) и обучать с данными

#### 4. **Guided Neural Networks**
- SOAR/ACT-R генерирует структуру, нейронные сети заполняют детали
- Пример: "Если видишь светофор, то..." (правило) + CNN распознает светофор

---

**Что решают нейро-символьные системы?**

| Проблема | Чистые нейронные | Чистые символьные | Нейро-символьные |
|----------|------------------|-------------------|------------------|
| Обучение из данных | 🟢 Отлично | 🔴 Плохо | 🟢 Отлично |
| Логическое рассуждение | 🔴 Плохо | 🟢 Отлично | 🟢 Отлично |
| Объяснимость | 🔴 Black box | 🟢 Высокая | 🟢 Высокая |
| Обобщение | 🟢 Хорошо | 🔴 Плохо | 🟢 Отлично |
| Каузальность | 🔴 Нет | 🟢 Есть | 🟢 Есть |
| Работа с восприятием | 🟢 Отлично | 🔴 Плохо | 🟢 Отлично |

---

**Примеры реальных систем**:

**AlphaGeometry (Google DeepMind, 2024)**:
- Решает олимпиадные задачи по геометрии
- Нейронная сеть предлагает конструкции
- Символьный движок проверяет доказательства
- **Результат**: уровень золотой медали на IMO

**OpenAI Codex + Formal Verification**:
- Codex генерирует код (нейронная сеть)
- Формальная верификация проверяет корректность (символьная)
- **Результат**: гарантированно безопасный код

**Embodied AI (роботы)**:
- Нейронные сети для восприятия (зрение, звук)
- Символьное планирование (PDDL, BDI)
- **Результат**: роботы, понимающие команды и действующие безопасно

---

**Будущее: AGI потребует когнитивной архитектуры**

**Гипотеза** (Gary Marcus, Yoshua Bengio):
- AGI не достичь только масштабированием LLM
- Нужна **гибридная архитектура**:
  - Быстрое обучение (нейронные сети)
  - Структурированное знание (онтологии, графы)
  - Рассуждение (логические движки)
  - Память (эпизодическая, процедурная)
  - Целенаправленность (BDI)

**Пример будущей архитектуры**:
```
Восприятие (CNN, transformers)
    ↓
Beliefs (Knowledge Graph + LLM)
    ↓
Reasoning (Symbolic engine + Neural inference)
    ↓
Planning (BDI + Monte Carlo Tree Search)
    ↓
Action (RL policies + Safety verification)
    ↓
Learning (Chunking + Backprop + Meta-learning)
```

**Вывод**: Нейро-символьные когнитивные архитектуры — путь к **надежному**, **объяснимому** и **общему** AI.
</details>

---

## 🛠️ ПРАКТИЧЕСКИЕ ЗАДАНИЯ

### Задание 1 (Базовое): Сравнительная таблица когнитивных архитектур
**⏱️ Время**: 20 минут
**🎯 Цель**: Систематизировать знания о трех основных архитектурах

**Задача**:
Создайте сравнительную таблицу SOAR, ACT-R и BDI по следующим критериям:
1. Основная философия (ключевая идея архитектуры)
2. Типы памяти (какие используются)
3. Механизм обучения (как агент улучшается)
4. Сильные стороны (где лучше всего применять)
5. Слабые стороны (ограничения)
6. Примеры применения (реальные системы)

**Формат таблицы**:
```markdown
| Критерий | SOAR | ACT-R | BDI |
|----------|------|-------|-----|
| Философия | ... | ... | ... |
| Память | ... | ... | ... |
| Обучение | ... | ... | ... |
| Сильные стороны | ... | ... | ... |
| Слабые стороны | ... | ... | ... |
| Применение | ... | ... | ... |
```

**Дополнительно** (по желанию):
- Добавьте столбец "LLM-гибрид" с вашими идеями об интеграции с LLM
- Оцените по 5-балльной шкале каждую архитектуру для: обучения, объяснимости, скорости, мультиагентности

**Ожидаемый результат**:
- Четкая таблица на 1 страницу
- Краткие, но информативные описания (2-3 предложения на ячейку)
- Понимание, когда какую архитектуру выбрать

---

### Задание 2 (Продвинутое): Выбор архитектуры для конкретной задачи
**⏱️ Время**: 35 минут
**🎯 Цель**: Научиться обоснованно выбирать архитектуру под задачу

**Сценарии** (выберите 2 из 4):

#### Сценарий A: Автономный робот-помощник в доме
**Описание**:
- Робот должен помогать по хозяйству (приносить предметы, убирать)
- Получает голосовые команды от пользователя
- Должен самостоятельно планировать маршруты
- Обучается предпочтениям пользователя
- Работает в динамичной среде (люди перемещаются, предметы переставляются)

**Ваша задача**:
1. Выбрать архитектуру (SOAR, ACT-R, BDI или гибрид)
2. Обосновать выбор (3-5 критериев)
3. Описать, как ключевые компоненты архитектуры решают задачи робота
4. Указать потенциальные проблемы и способы их решения

---

#### Сценарий B: Интеллектуальный тьютор для программирования
**Описание**:
- Система обучает новичков программированию на Python
- Должна понимать ошибки студента и объяснять их
- Адаптирует сложность заданий под уровень студента
- Предсказывает, какие темы вызовут сложности
- Нужна высокая точность моделирования времени ответа студента

**Ваша задача**:
1. Выбрать архитектуру (SOAR, ACT-R, BDI или гибрид)
2. Обосновать выбор (3-5 критериев)
3. Описать, как ключевые компоненты архитектуры решают задачи тьютора
4. Привести пример: студент делает ошибку — как система реагирует?

---

#### Сценарий C: Мультиагентная система управления дронами
**Описание**:
- 10 дронов должны совместно обследовать зону бедствия
- Каждый дроне автономен, но может коммуницировать с другими
- Цели динамические (новые области приоритета появляются)
- Дроны могут выходить из строя (нужна устойчивость)
- Требуется быстрое перепланирование

**Ваша задача**:
1. Выбрать архитектуру (SOAR, ACT-R, BDI или гибрид)
2. Обосновать выбор (3-5 критериев)
3. Описать, как дроны координируются через архитектуру
4. Как система справляется с выходом дрона из строя?

---

#### Сценарий D: AI для медицинской диагностики
**Описание**:
- Система анализирует симптомы и предлагает диагноз
- Должна объяснить свое решение (для врачей)
- Работает с неопределенностью (неполные данные)
- Обучается на новых случаях
- Критична надежность и объяснимость

**Ваша задача**:
1. Выбрать архитектуру (SOAR, ACT-R, BDI или гибрид)
2. Обосновать выбор (3-5 критериев)
3. Как архитектура обеспечивает объяснимость?
4. Как интегрировать LLM для обработки текстовых описаний симптомов?

---

**Формат ответа** (для каждого выбранного сценария):

```markdown
### Сценарий: [Название]

**Выбранная архитектура**: [SOAR / ACT-R / BDI / Гибрид]

**Обоснование**:
1. [Критерий 1]: [почему архитектура подходит]
2. [Критерий 2]: ...
3. ...

**Применение компонентов архитектуры**:
- **[Компонент 1]**: [как используется в задаче]
- **[Компонент 2]**: ...

**Пример работы**:
[Конкретный сценарий: вход → обработка → выход]

**Потенциальные проблемы**:
- [Проблема 1]: [как решить]
- [Проблема 2]: ...
```

**Ожидаемый результат**:
- 2 развернутых анализа (по ~1 странице каждый)
- Четкое понимание trade-offs разных архитектур
- Способность обосновывать архитектурные решения

---

### Задание 3 (Проектное): Гибридная когнитивная архитектура
**⏱️ Время**: 60 минут
**🎯 Цель**: Спроектировать новую архитектуру, объединяющую сильные стороны нескольких подходов

**Задача**:
Разработайте гибридную когнитивную архитектуру для **персонального AI-ассистента** (например, улучшенная версия Siri/Alexa), которая объединяет:
- Элементы SOAR (универсальное решение проблем)
- Элементы ACT-R (моделирование пользователя)
- Элементы BDI (управление целями)
- Современные LLM (обработка языка, генерация)

**Требования к ассистенту**:
1. **Понимание естественного языка** (голосовые команды, диалоги)
2. **Долговременная память** о пользователе (предпочтения, расписание, контакты)
3. **Проактивность** (сам предлагает действия, например, "пора выходить, пробки")
4. **Обучение** на взаимодействиях (запоминает, как пользователь любит формулировки)
5. **Объяснимость** ("почему ты предложил это?")
6. **Мультимодальность** (текст, голос, изображения)

**Структура проекта**:

#### Часть 1: Архитектурная диаграмма
Нарисуйте (или опишите текстом) схему с компонентами:
- Модули восприятия (speech-to-text, vision, ...)
- Память (рабочая, долговременная, эпизодическая)
- Рассуждение (какая архитектура за что отвечает)
- Планирование и действия
- Обучение
- Взаимодействие между модулями

**Пример текстового описания**:
```
[Speech Input] → [LLM Processing] → [BDI Beliefs Update]
                                          ↓
[User Model (ACT-R)] ← [Working Memory (SOAR)]
        ↓                       ↓
[Desire Generation] → [SOAR Problem Solving] → [Plan]
        ↓
[Action Execution (LLM Generation)] → [Speech Output]
        ↓
[Episodic Memory (ACT-R)] ← [Chunking (SOAR)]
```

---

#### Часть 2: Описание компонентов

Для каждого компонента укажите:
- **Какая архитектура** лежит в основе (SOAR/ACT-R/BDI/LLM)
- **Роль** в системе
- **Как взаимодействует** с другими компонентами

**Пример**:
```markdown
**Компонент: User Model**
- **Архитектура**: ACT-R
- **Роль**: Моделирует предпочтения пользователя (activation chunks)
- **Взаимодействие**:
  - Получает от BDI текущие beliefs
  - Вычисляет активацию предпочтений
  - Передает SOAR для формирования операторов
```

---

#### Часть 3: Сценарий работы

Опишите детально, как система обрабатывает команду:

**Пример сценария**:
```
Пользователь: "Напомни мне купить молоко"

Шаг 1: [Speech-to-text] → текст: "Напомни мне купить молоко"

Шаг 2: [LLM Processing] → intent: create_reminder, entity: "молоко"

Шаг 3: [BDI Beliefs Update]
- Beliefs: {user_location: home, time: 18:00}
- Desire: create_reminder("молоко")

Шаг 4: [ACT-R User Model]
- Проверка: activation("молоко | grocery") = 4.2 (высокая)
- Вывод: пользователь часто покупает молоко → важно

Шаг 5: [SOAR Problem Solving]
- Impasse: Когда напомнить?
- Operators: [напомнить сейчас, напомнить вечером, напомнить у магазина]
- Выбор: "напомнить у магазина" (на основе chunk: user обычно покупает по дороге домой)

Шаг 6: [BDI Intention]
- Intention: create_reminder("молоко", trigger="near grocery store")

Шаг 7: [Action Execution]
- LLM генерирует ответ: "Хорошо, я напомню, когда вы будете рядом с магазином"
- Сохранение в Episodic Memory

Шаг 8: [Learning]
- SOAR chunking: ЕСЛИ (пользователь просит напомнить о продукте) ТО (привязать к магазину)
- ACT-R utility: увеличить полезность оператора "напомнить у магазина"
```

---

#### Часть 4: Преимущества гибридного подхода

Объясните, **почему** гибридная архитектура лучше, чем:
1. Чистый LLM (например, ChatGPT без памяти)
2. Чистая BDI (без обучения)
3. Чистая SOAR (без языковой модели)

**Формат**:
```markdown
**vs Чистый LLM**:
- Проблема LLM: [например, нет долговременной памяти]
- Решение гибрида: [ACT-R episodic memory + векторная БД]

**vs Чистая BDI**:
- Проблема BDI: [например, нет автоматического обучения]
- Решение гибрида: [SOAR chunking + LLM fine-tuning]

...
```

---

#### Часть 5: Реализация (псевдокод)

Напишите высокоуровневый псевдокод основного цикла агента:

```python
class HybridAssistant:
    def __init__(self):
        self.bdi = BDI()
        self.soar = SOAR()
        self.act_r = ACTR()
        self.llm = GPT4()

    def process_command(self, speech_input):
        # 1. Восприятие
        text = speech_to_text(speech_input)
        intent = self.llm.extract_intent(text)

        # 2. Обновление Beliefs (BDI)
        self.bdi.update_beliefs(intent)

        # 3. Проверка User Model (ACT-R)
        user_context = self.act_r.get_context(intent)

        # 4. Генерация Desires (BDI + LLM)
        desires = self.bdi.generate_desires()
        llm_suggestions = self.llm.suggest_goals(desires, user_context)

        # 5. Problem Solving (SOAR)
        if self.soar.has_impasse():
            operators = self.llm.generate_operators(self.soar.state)
            self.soar.add_operators(operators)

        best_operator = self.soar.decide()

        # 6. Intention Formation (BDI)
        self.bdi.commit_intention(best_operator)

        # 7. Plan Execution
        plan = self.bdi.get_plan(best_operator)
        action = self.execute_plan(plan)

        # 8. Response Generation (LLM)
        response = self.llm.generate_response(action, user_context)

        # 9. Learning
        self.soar.learn_chunk(intent, best_operator, action)
        self.act_r.update_activation(intent)

        # 10. Memory Storage
        self.act_r.store_episode({
            "input": text,
            "intent": intent,
            "action": action,
            "time": now()
        })

        return response
```

---

**Формат сдачи проекта**:
- **Часть 1**: Диаграмма (можно текстом в ASCII или ссылка на рисунок)
- **Часть 2**: Описание компонентов (5-7 компонентов)
- **Часть 3**: Детальный сценарий работы (1 пример)
- **Часть 4**: Сравнительный анализ (3 пункта)
- **Часть 5**: Псевдокод (основной цикл + 2-3 ключевые функции)

**Объем**: 3-4 страницы

**Критерии оценки**:
- ✅ Логичность интеграции архитектур (каждая используется по назначению)
- ✅ Детальность сценария (понятны все шаги)
- ✅ Обоснованность преимуществ (сравнение с базовыми подходами)
- ✅ Реализуемость (псевдокод можно превратить в код)
- ✅ Творческий подход (оригинальные решения приветствуются)

**Дополнительные баллы** (по желанию):
- Реализация одного компонента в коде (Python)
- Добавление механизма обработки ошибок и противоречий
- Описание, как система справляется с edge cases (например, команда на незнакомом языке)

---

## 📚 НАВИГАЦИЯ

**← Предыдущая глава**: [[09-ЭТИКА-И-БЕЗОПАСНОСТЬ-АГЕНТОВ.md|09 - Этика и безопасность агентов]]

**→ Следующая глава**: [[11-ОГРАНИЧЕНИЯ-И-ПРОБЛЕМЫ-АГЕНТОВ.md|11 - Ограничения и проблемы агентов]]

**↑ К оглавлению**: [[00-ОГЛАВЛЕНИЕ|Оглавление курса "Агентное кодирование"]]

---

**Следующая глава**: [[11-ОГРАНИЧЕНИЯ-И-ПРОБЛЕМЫ-АГЕНТОВ.md|11 - ОГРАНИЧЕНИЯ И ПРОБЛЕМЫ АГЕНТОВ]]

Мы узнаем о **реальных вызовах** агентных систем: безопасность, этика, предсказуемость, контроль — критические аспекты для применения в продакшене.

---

*Конец Главы 10*
